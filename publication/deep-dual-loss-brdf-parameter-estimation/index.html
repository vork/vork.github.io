<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.1.0 for Hugo"><meta name=google-site-verification content="S4KoopgNiTG4YgetELfTyLoFaDS9bHbC3gJBOdfft3o"><meta name=author content="Mark Boss"><meta name=description content="Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. We propose a method which utilizes an encoder-decoder Convolutional Neural Network (CNN) to extract parameters for the Bidirectional Reflectance Distribution Function (BRDF) automatically from a sparse sample set. This is done by implementing a differentiable renderer, which allows for a loss backpropagation of rendered images. This photometric loss is essential because defining a numerical BRDF distance metric is difficult. A second loss is added, which compares the parameters maps directly. Therefore, the statistical properties of the BRDF model are learned, which reduces artifacts in the predicted parameters. This dual loss principal improves the result of the network significantly. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF (SVBRDF) parameters with a sufficiently high resolution for intended real-world usage. The capture process for materials only requires five known light positions with a fixed camera position. This reduces the scanning time drastically, and a material sample can be obtained in seconds with an automated system."><link rel=alternate hreflang=en-us href=https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#009688"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&family=Cutive+Mono&family=Raleway:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&family=Cutive+Mono&family=Raleway:wght@400;700&display=swap" media=print onload="this.media='all'"><link rel=stylesheet href=/css/wowchemy.ca412ef352c1ca0efcb205a98abc4014.css><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@markb_boss"><meta property="twitter:creator" content="@markb_boss"><meta property="og:site_name" content="Mark Boss"><meta property="og:url" content="https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/"><meta property="og:title" content="Deep Dual Loss BRDF Parameter Estimation | Mark Boss"><meta property="og:description" content="Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. We propose a method which utilizes an encoder-decoder Convolutional Neural Network (CNN) to extract parameters for the Bidirectional Reflectance Distribution Function (BRDF) automatically from a sparse sample set. This is done by implementing a differentiable renderer, which allows for a loss backpropagation of rendered images. This photometric loss is essential because defining a numerical BRDF distance metric is difficult. A second loss is added, which compares the parameters maps directly. Therefore, the statistical properties of the BRDF model are learned, which reduces artifacts in the predicted parameters. This dual loss principal improves the result of the network significantly. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF (SVBRDF) parameters with a sufficiently high resolution for intended real-world usage. The capture process for materials only requires five known light positions with a fixed camera position. This reduces the scanning time drastically, and a material sample can be obtained in seconds with an automated system."><meta property="og:image" content="https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/featured.jpg"><meta property="twitter:image" content="https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2017-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2018-07-01T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/"},"headline":"Deep Dual Loss BRDF Parameter Estimation","image":["https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/featured.jpg"],"datePublished":"2017-01-01T00:00:00Z","dateModified":"2018-07-01T00:00:00Z","author":{"@type":"Person","name":"Mark Boss"},"publisher":{"@type":"Organization","name":"Mark Boss","logo":{"@type":"ImageObject","url":"https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_192x192_fill_lanczos_center_2.png"}},"description":"Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. We propose a method which utilizes an encoder-decoder Convolutional Neural Network (CNN) to extract parameters for the Bidirectional Reflectance Distribution Function (BRDF) automatically from a sparse sample set. This is done by implementing a differentiable renderer, which allows for a loss backpropagation of rendered images. This photometric loss is essential because defining a numerical BRDF distance metric is difficult. A second loss is added, which compares the parameters maps directly. Therefore, the statistical properties of the BRDF model are learned, which reduces artifacts in the predicted parameters. This dual loss principal improves the result of the network significantly. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF (SVBRDF) parameters with a sufficiently high resolution for intended real-world usage. The capture process for materials only requires five known light positions with a fixed camera position. This reduces the scanning time drastically, and a material sample can be obtained in seconds with an automated system."}</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=all onload="this.media='all'"><meta name=msvalidate.01 content="2625B23426FAE2D4025878BAF046F9A0"><title>Deep Dual Loss BRDF Parameter Estimation | Mark Boss</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=2c17505f22b1b0ca69d3e04d1557f1d5><script src=/js/wowchemy-init.min.226a9011996d125bf3fe4a5f22353a49.js></script><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Mark Boss</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Mark Boss</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#featured_publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Deep Dual Loss BRDF Parameter Estimation</h1><div class=article-metadata><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/fabian-groh/>Fabian Groh</a></span>, <span><a href=/author/sebastian-herholz/>Sebastian Herholz</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div><span class=article-date>July 2018</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/files/deep_dual_loss_brdf_egsr_mam_2018.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/deep-dual-loss-brdf-parameter-estimation/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header" href=https://doi.org/10.2312/mam.20181199 target=_blank rel=noopener>DOI</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:352px><div style=position:relative><img src=/publication/deep-dual-loss-brdf-parameter-estimation/featured_hu30910665284931ace4f57faa1e01d828_98512_720x0_resize_q80_lanczos.jpg alt="Overview of the network architecture and loss design." class=featured-image>
<span class=article-header-caption>The proposed network architecture and loss design.</span></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. We propose a method which utilizes an encoder-decoder Convolutional Neural Network (CNN) to extract parameters for the Bidirectional Reflectance Distribution Function (BRDF) automatically from a sparse sample set. This is done by implementing a differentiable renderer, which allows for a loss backpropagation of rendered images. This photometric loss is essential because defining a numerical BRDF distance metric is difficult. A second loss is added, which compares the parameters maps directly. Therefore, the statistical properties of the BRDF model are learned, which reduces artifacts in the predicted parameters. This dual loss principal improves the result of the network significantly. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF (SVBRDF) parameters with a sufficiently high resolution for intended real-world usage. The capture process for materials only requires five known light positions with a fixed camera position. This reduces the scanning time drastically, and a material sample can be obtained in seconds with an automated system.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#1>Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">In Workshop on Material Appearance Modeling</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/material-acquisition/>Material Acquisition</a>
<a class="badge badge-light" href=/tag/machine-learning/>Machine Learning</a>
<a class="badge badge-light" href=/tag/multi-shot/>Multi-Shot</a>
<a class="badge badge-light" href=/tag/flat-surface/>Flat Surface</a>
<a class="badge badge-light" href=/tag/svbrdf/>SVBRDF</a></div><div class="media author-card content-widget-hr"><a href=https://markboss.me/><img class="avatar mr-3 avatar-circle" src=/author/mark-boss/avatar_hu8228efeb083742449721d94a9befbadd_1942861_270x270_fill_q80_lanczos_center.jpg alt="Mark Boss"></a><div class=media-body><h5 class=card-title><a href=https://markboss.me/>Mark Boss</a></h5><h6 class=card-subtitle>Ph.D. Student</h6><p class=card-text>I&rsquo;m a Ph.D. student at the University of Tübingen with research interests in the intersection of machine learning and computer graphics.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:hello@markboss.me><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/markb_boss target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=y23cQ6wAAAAJ&hl=en" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/vork target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/markbboss target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/files/cv.pdf><i class="ai ai-cv"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/publication/master_thesis/>CNN-based BRDF parameter estimation</a></li><li><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/>Single Image BRDF Parameter Estimation with a Conditional Adversarial Network</a></li><li><a href=/publication/2021-nerd/>NeRD: Neural Reflectance Decomposition from Image Collections</a></li><li><a href=/publication/cvpr20-two-shot-brdf/>Two-shot Spatially-varying BRDF and Shape Estimation</a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/privacy/>Privacy Policy</a>
&#183;
<a href=/terms/>Legal details</a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=/js/bootstrap.bundle.min.6aed84840afc03ab4d5750157f69c120.js></script><script src=/en/js/wowchemy.min.9354809e0cd8454facc06cd597501cd6.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script></body></html>