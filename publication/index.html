<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.6"><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.4228702cea630023ae1883491e9ef88b.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=google-site-verification content="S4KoopgNiTG4YgetELfTyLoFaDS9bHbC3gJBOdfft3o"><meta name=msvalidate.01 content="2625B23426FAE2D4025878BAF046F9A0"><meta name=author content="Mark Boss"><meta name=description content="Personal Research Website of Mark Boss"><link rel=alternate hreflang=en-us href=https://markboss.me/publication/><link rel=canonical href=https://markboss.me/publication/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#009688"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@markb_boss"><meta property="twitter:creator" content="@markb_boss"><meta property="twitter:image" content="https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_512x512_fill_lanczos_center_3.png"><meta property="og:type" content="website"><meta property="og:site_name" content="Mark Boss"><meta property="og:url" content="https://markboss.me/publication/"><meta property="og:title" content="Publications | Mark Boss"><meta property="og:description" content="Personal Research Website of Mark Boss"><meta property="og:image" content="https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-03-18T00:00:00+00:00"><link rel=alternate href=/publication/index.xml type=application/rss+xml title="Mark Boss"><title>Publications | Mark Boss</title>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css crossorigin=anonymous media=print onload='this.media="all"' integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw=="></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=3a079e7dad19be978a318345a7749d34><script src=/js/wowchemy-init.min.e1d05065ea0d70e40dcd8bf319bec2e9.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Mark Boss</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Mark Boss</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/files/cv.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class="universal-wrapper pt-3"><h1>Publications</h1></div><div class=universal-wrapper><div class=row><div class=col-lg-12><div class="form-row mb-4"><div class=col-auto><input type=search class="filter-search form-control form-control-sm" placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off role=textbox spellcheck=false></div><div class=col-auto><select class="pub-filters pubtype-select form-control form-control-sm" data-filter-group=pubtype><option value=*>Type</option><option value=.pubtype-article>Preprint</option><option value=.pubtype-article-journal>Journal article</option><option value=.pubtype-paper-conference>Conference paper</option><option value=.pubtype-thesis>Thesis</option></select></div><div class=col-auto><select class="pub-filters form-control form-control-sm" data-filter-group=year><option value=*>Date</option><option value=.year-2024>2024</option><option value=.year-2023>2023</option><option value=.year-2022>2022</option><option value=.year-2021>2021</option><option value=.year-2020>2020</option><option value=.year-2019>2019</option><option value=.year-2018>2018</option></select></div></div><div id=container-publications><div class="grid-sizer col-lg-12 isotope-item pubtype-article year-2024"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2024-sv3d/>SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion</a></div><a href=/publication/2024-sv3d/ class=summary-link><div class=article-style>We present Stable Video 3D (SV3D) - a latent video diffusion model for high-resolution, image-to-multi-view generation of orbital …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/vikram-voleti/>Vikram Voleti</a></span>, <span><a href=/author/chun-han-yao/>Chun-Han Yao</a></span>, <span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/adam-letts/>Adam Letts</a></span>, <span><a href=/author/david-pankratz/>David Pankratz</a></span>, <span><a href=/author/dmitrii-tochilkin/>Dmitrii Tochilkin</a></span>, <span><a href=/author/christian-laforte/>Christian Laforte</a></span>, <span><a href=/author/robin-rombach/>Robin Rombach</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2024-sv3d/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://stability.ai/s/SV3D_report.pdf target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://sv3d.github.io/ target=_blank rel=noopener><i class="fab fa-browser mr-1"></i>Website</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/Zqw4-1LcfWg target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a></div></div><div class=ml-3><a href=/publication/2024-sv3d/><img src=/publication/2024-sv3d/featured_hu9e461223b7ede27ad582e3af118936ad_541487_8b218467354db93580e5a361c4b08337.webp height=46 width=150 alt="SV3D: Novel Multi-view Synthesis and 3D Generation from a Single Image using Latent Video Diffusion" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-article year-2024"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2024-pbr-collab-control/>Collaborative Control for Geometry-Conditioned PBR Image Generation</a></div><a href=/publication/2024-pbr-collab-control/ class=summary-link><div class=article-style>Current 3D content generation builds on generative models that output RGB images. Modern graphics pipelines, however, require …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/shimon-vainer/>Shimon Vainer</a></span>, <span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/mathias-parger/>Mathias Parger</a></span>, <span><a href=/author/konstantin-kutsy/>Konstantin Kutsy</a></span>, <span><a href=/author/dante-de-nigris/>Dante De Nigris</a></span>, <span><a href=/author/ciara-rowles/>Ciara Rowles</a></span>, <span><a href=/author/nicolas-perony/>Nicolas Perony</a></span>, <span><a href=/author/simon-donne/>Simon Donné</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2024-pbr-collab-control/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.05919 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://unity-research.github.io/holo-gen/ target=_blank rel=noopener><i class="fab fa-browser mr-1"></i>Website</a></div></div><div class=ml-3><a href=/publication/2024-pbr-collab-control/><img src=/publication/2024-pbr-collab-control/featured_hua2d832bd04dce210763d3ddbd4ba53f7_342061_66e216412fde3f5a663b16399703a7a8.webp height=75 width=150 alt="Collaborative Control for Geometry-Conditioned PBR Image Generation" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-article year-2024"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2024-shinobi/>SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild</a></div><a href=/publication/2024-shinobi/ class=summary-link><div class=article-style>We present SHINOBI, an end-to-end framework for the reconstruction of shape, material, and illumination from object images captured …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/andreas-engelhardt/>Andreas Engelhardt</a></span>, <span><a href=/author/amit-raj/>Amit Raj</a></span>, <span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/yunzhi-zhang/>Yunzhi Zhang</a></span>, <span><a href=/author/abhishek-kar/>Abhishek Kar</a></span>, <span><a href=/author/yuanzhen-li/>Yuanzhen Li</a></span>, <span><a href=/author/deqing-sun/>Deqing Sun</a></span>, <span><a href=/author/ricardo-martin-brualla/>Ricardo Martin Brualla</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2024-shinobi/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2401.10171 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.youtube.com/watch?v=iFENQ6AcYd8" target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://shinobi.aengelhardt.com/ target=_blank rel=noopener><i class="fab fa-browser mr-1"></i>Website</a></div></div><div class=ml-3><a href=/publication/2024-shinobi/><img src=/publication/2024-shinobi/featured_hu8f4ab94836ed4264f7845ce06607b728_162833_619d2f4321dce6d0b87f825faac4cc1f.webp height=52 width=150 alt="SHINOBI: Shape and Illumination using Neural Object Decomposition via BRDF Optimization In-the-wild" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-thesis year-2023"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/phdthesis/>Neural Reflectance Decomposition</a></div><a href=/publication/phdthesis/ class=summary-link><div class=article-style>Creating relightable objects from images or collections is a fundamental challenge in computer vision and graphics. This problem is …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/phdthesis/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talks/phd_defense/ target=_blank rel=noopener>Slides
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=http://dx.doi.org/10.15496/publikation-79535 target=_blank rel=noopener><i class="fas fa-pdf mr-1"></i>Publication</a></div></div><div class=ml-3><a href=/publication/phdthesis/><img src=/publication/phdthesis/featured_hu24f1a4c7f360f896f1c8f317261b8f5f_71752_c73aff9b98f3c33565ed946842fb7575.webp height=123 width=150 alt="Neural Reflectance Decomposition" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2022"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022-samurai/>SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections</a></div><a href=/publication/2022-samurai/ class=summary-link><div class=article-style>Inverse rendering of an object under entirely unknown capture conditions is a fundamental challenge in computer vision and graphics. …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/andreas-engelhardt/>Andreas Engelhardt</a></span>, <span><a href=/author/abhishek-kar/>Abhishek Kar</a></span>, <span><a href=/author/yuanzhen-li/>Yuanzhen Li</a></span>, <span><a href=/author/deqing-sun/>Deqing Sun</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022-samurai/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talks/samurai_neurips/ target=_blank rel=noopener>Slides
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2205.15768 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/LlYuGDjXp-8 target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/google/samurai target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://www.dropbox.com/sh/x3u2szvaqjtaykl/AACCZn05NciMa5bHhn60p9vja?dl=0" target=_blank rel=noopener><i class="fas fa-database mr-1"></i>Scenes</a></div></div><div class=ml-3><a href=/publication/2022-samurai/><img src=/publication/2022-samurai/featured_hueebc0576a6a37e9404d18d9e27e81796_130114_4a8b21b7b1eb6145c6b3ac6f41c47476.webp height=55 width=150 alt="SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-article-journal year-2022"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022-tlcyzer/>An open-source smartphone app for the quantitative evaluation of thin-layer chromatographic analyses in medicine quality screening</a></div><a href=/publication/2022-tlcyzer/ class=summary-link><div class=article-style>Substandard and falsified medicines present a serious threat to public health. Simple, low-cost screening tools are important in the …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/cathrin-hauk/>Cathrin Hauk</a></span>, <span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/julia-gabel/>Julia Gabel</a></span>, <span><a href=/author/simon-schafermann/>Simon Schäfermann</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/lutz-heide/>Lutz Heide</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022-tlcyzer/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/tlcyzer/>Project
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1038/s41598-022-17527-y target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/TLCyzer/tlcyzer target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://tlcyzer.github.io target=_blank rel=noopener><i class="fab fa-browser mr-1"></i>Website</a></div></div><div class=ml-3><a href=/publication/2022-tlcyzer/><img src=/publication/2022-tlcyzer/featured_hu3ded59b12af0e577d0f6c9ba658bb523_562259_378ef30f17ca6b5e47e7e7513ebfc489.webp height=128 width=150 alt="An open-source smartphone app for the quantitative evaluation of thin-layer chromatographic analyses in medicine quality screening" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2021"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2021-neural-pil/>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</a></div><a href=/publication/2021-neural-pil/ class=summary-link><div class=article-style>Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/raphael-braun/>Raphael Braun</a></span>, <span><a href=/author/ce-liu/>Ce Liu</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2021-neural-pil/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2110.14373 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/p5cKaNwVp4M target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cgtuebingen/Neural-PIL target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a></div></div><div class=ml-3><a href=/publication/2021-neural-pil/><img src=/publication/2021-neural-pil/featured_hu557982f4a73d07f363dd1cf0452a897a_50708_f1821e1f7d6cc23918cc45308d6376e7.webp height=40 width=150 alt="Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2020"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2021-nerd/>NeRD: Neural Reflectance Decomposition from Image Collections</a></div><a href=/publication/2021-nerd/ class=summary-link><div class=article-style>Decomposing a scene into its shape, reflectance, and illumination is a challenging but important problem in computer vision and …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/raphael-braun/>Raphael Braun</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/ce-liu/>Ce Liu</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2021-nerd/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2012.03918 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/JL-qMTXw9VU target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition#datasets target=_blank rel=noopener><i class="fas fa-database mr-1"></i>Dataset</a></div></div><div class=ml-3><a href=/publication/2021-nerd/><img src=/publication/2021-nerd/featured_hu9ce3dee256724e8b0641511e91e45d8f_249226_f4e749fb1c920e262a027e81e580234b.webp height=50 width=150 alt="NeRD: Neural Reflectance Decomposition from Image Collections" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2020"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/cvpr20-two-shot-brdf/>Two-shot Spatially-varying BRDF and Shape Estimation</a></div><a href=/publication/cvpr20-two-shot-brdf/ class=summary-link><div class=article-style>Capturing the shape and spatially-varying appearance (SVBRDF) of an object from images is a challenging task that has applications in …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/kihwan-kim/>Kihwan Kim</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/jan-kautz/>Jan Kautz</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/cvpr20-two-shot-brdf/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/files/cvpr20-two-shot-brdf.pdf><i class="fas fa-file-pdf mr-1"></i>Paper + Supplementary</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2004.00403 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/CyC6PutoJO8 target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/NVlabs/two-shot-brdf-shape target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/14mou3Va65deimPYE5GtFdK8OS3I0BSzq/view?usp=sharing" target=_blank rel=noopener><i class="fas fa-database mr-1"></i>Dataset</a></div></div><div class=ml-3><a href=/publication/cvpr20-two-shot-brdf/><img src=/publication/cvpr20-two-shot-brdf/featured_hu30910665284931ace4f57faa1e01d828_139209_3b520930509e00a09be3273f9acb7b31.webp height=65 width=150 alt="Two-shot Spatially-varying BRDF and Shape Estimation" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-article year-2019"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/>Single Image BRDF Parameter Estimation with a Conditional Adversarial Network</a></div><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/ class=summary-link><div class=article-style>Creating plausible surfaces is an essential component in achieving a high degree of realism in rendering. To relieve artists, who …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1910.05148 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/><img src=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/featured_hu30910665284931ace4f57faa1e01d828_105779_8b6c4eb257ff41379a53062474493fe6.webp height=84 width=150 alt="Single Image BRDF Parameter Estimation with a Conditional Adversarial Network" loading=lazy></a></div></div></div><div class="grid-sizer col-lg-12 isotope-item pubtype-paper-conference year-2018"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/deep-dual-loss-brdf-parameter-estimation/>Deep Dual Loss BRDF Parameter Estimation</a></div><a href=/publication/deep-dual-loss-brdf-parameter-estimation/ class=summary-link><div class=article-style>Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/fabian-groh/>Fabian Groh</a></span>, <span><a href=/author/sebastian-herholz/>Sebastian Herholz</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/files/deep_dual_loss_brdf_egsr_mam_2018.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/deep-dual-loss-brdf-parameter-estimation/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.2312/mam.20181199 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/deep-dual-loss-brdf-parameter-estimation/><img src=/publication/deep-dual-loss-brdf-parameter-estimation/featured_hu30910665284931ace4f57faa1e01d828_98512_d024b268d3cc764f797023b67dc74990.webp height=73 width=150 alt="Deep Dual Loss BRDF Parameter Estimation" loading=lazy></a></div></div></div></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/privacy/>Privacy Policy</a>
&#183;
<a href=/terms/>Legal details</a></p><p class="powered-by copyright-license-text">© 2024 Mark Boss. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> — the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js></script><script src=https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.62586ca65ca61821fe707eb9fa6268b7.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin=anonymous></script></body></html>