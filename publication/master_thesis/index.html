<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.3.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&family=Cutive+Mono&family=Raleway:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Bitter:ital,wght@0,400;0,700;1,400&family=Cutive+Mono&family=Raleway:wght@400;700&display=swap" media=print onload="this.media='all'"><meta name=google-site-verification content="S4KoopgNiTG4YgetELfTyLoFaDS9bHbC3gJBOdfft3o"><meta name=msvalidate.01 content="2625B23426FAE2D4025878BAF046F9A0"><meta name=author content="Mark Boss"><meta name=description content="The behavior of surfaces is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. Thus, in this thesis a method which utilizes an encoder-decoder Convolutional Neural Networks (CNN) to extract information of the Bidirectional Reflectance Distribution Function (BRDF) automatically is proposed. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF-parameters with a sufficiently high resolution for real-world usage. The capture process for materials only requires five known light positions with a fixed camera position and thus can be acquired even in a mobile setup. This reduces the scanning time drastically and a material sample can be obtained in seconds with an automated system."><link rel=alternate hreflang=en-us href=https://markboss.me/publication/master_thesis/><meta name=theme-color content="#009688"><link rel=stylesheet href=/css/vendor-bundle.min.f1ecf783c14edc00c9320c205831ad8e.css media=print onload="this.media='all'"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload="this.media='all'"><link rel=stylesheet href=/css/wowchemy.c2ac0b6950cea6447b36a29a23a6d3a2.css><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_180x180_fill_lanczos_center_2.png><link rel=canonical href=https://markboss.me/publication/master_thesis/><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@markb_boss"><meta property="twitter:creator" content="@markb_boss"><meta property="og:site_name" content="Mark Boss"><meta property="og:url" content="https://markboss.me/publication/master_thesis/"><meta property="og:title" content="CNN-based BRDF parameter estimation | Mark Boss"><meta property="og:description" content="The behavior of surfaces is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. Thus, in this thesis a method which utilizes an encoder-decoder Convolutional Neural Networks (CNN) to extract information of the Bidirectional Reflectance Distribution Function (BRDF) automatically is proposed. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF-parameters with a sufficiently high resolution for real-world usage. The capture process for materials only requires five known light positions with a fixed camera position and thus can be acquired even in a mobile setup. This reduces the scanning time drastically and a material sample can be obtained in seconds with an automated system."><meta property="og:image" content="https://markboss.me/publication/master_thesis/featured.jpg"><meta property="twitter:image" content="https://markboss.me/publication/master_thesis/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2017-01-01T00:00:00+00:00"><meta property="article:modified_time" content="2018-05-01T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://markboss.me/publication/master_thesis/"},"headline":"CNN-based BRDF parameter estimation","image":["https://markboss.me/publication/master_thesis/featured.jpg"],"datePublished":"2017-01-01T00:00:00Z","dateModified":"2018-05-01T00:00:00Z","author":{"@type":"Person","name":"Mark Boss"},"publisher":{"@type":"Organization","name":"Mark Boss","logo":{"@type":"ImageObject","url":"https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_192x192_fill_lanczos_center_2.png"}},"description":"The behavior of surfaces is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. Thus, in this thesis a method which utilizes an encoder-decoder Convolutional Neural Networks (CNN) to extract information of the Bidirectional Reflectance Distribution Function (BRDF) automatically is proposed. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF-parameters with a sufficiently high resolution for real-world usage. The capture process for materials only requires five known light positions with a fixed camera position and thus can be acquired even in a mobile setup. This reduces the scanning time drastically and a material sample can be obtained in seconds with an automated system."}</script><title>CNN-based BRDF parameter estimation | Mark Boss</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=3a9afb08e7d0d94f6bb3e8fb2337a5ad><script src=/js/wowchemy-init.min.2da3b1fa37e894630bf6de39b1b694b3.js></script><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Mark Boss</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Mark Boss</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#featured_publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#projects><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>CNN-based BRDF parameter estimation</h1><div class=article-metadata><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div><span class=article-date>May 2018</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/files/master_thesis.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/master_thesis/cite.bib>Cite</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:352px><div style=position:relative><img src=/publication/master_thesis/featured_hu30910665284931ace4f57faa1e01d828_98512_720x0_resize_q80_lanczos.jpg width=720 height=352 alt class=featured-image>
<span class=article-header-caption>The proposed network architecture and loss design.</span></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>The behavior of surfaces is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. Thus, in this thesis a method which utilizes an encoder-decoder Convolutional Neural Networks (CNN) to extract information of the Bidirectional Reflectance Distribution Function (BRDF) automatically is proposed. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF-parameters with a sufficiently high resolution for real-world usage. The capture process for materials only requires five known light positions with a fixed camera position and thus can be acquired even in a mobile setup. This reduces the scanning time drastically and a material sample can be obtained in seconds with an automated system.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#7>Thesis</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/material-acquisition/>Material Acquisition</a>
<a class="badge badge-light" href=/tag/machine-learning/>Machine Learning</a>
<a class="badge badge-light" href=/tag/multi-shot/>Multi-Shot</a>
<a class="badge badge-light" href=/tag/flat-surface/>Flat Surface</a>
<a class="badge badge-light" href=/tag/svbrdf/>SVBRDF</a></div><div class="media author-card content-widget-hr"><a href=https://markboss.me/><img class="avatar mr-3 avatar-circle" src=/author/mark-boss/avatar_hu8228efeb083742449721d94a9befbadd_1942861_270x270_fill_q80_lanczos_center.jpg alt="Mark Boss"></a><div class=media-body><h5 class=card-title><a href=https://markboss.me/>Mark Boss</a></h5><h6 class=card-subtitle>Ph.D. Student</h6><p class=card-text>I&rsquo;m a Ph.D. student at the University of Tübingen with research interests in the intersection of machine learning and computer graphics.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:hello@markboss.me><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/markb_boss target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=y23cQ6wAAAAJ&hl=en" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/vork target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/markbboss target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=/files/cv.pdf><i class="ai ai-cv"></i></a></li></ul></div></div><div class="article-widget content-widget-hr"><h3>Related</h3><ul><li><a href=/publication/deep-dual-loss-brdf-parameter-estimation/>Deep Dual Loss BRDF Parameter Estimation</a></li><li><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/>Single Image BRDF Parameter Estimation with a Conditional Adversarial Network</a></li><li><a href=/publication/2021-neural-pil/>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</a></li><li><a href=/publication/2021-nerd/>NeRD: Neural Reflectance Decomposition from Image Collections</a></li><li><a href=/publication/cvpr20-two-shot-brdf/>Two-shot Spatially-varying BRDF and Shape Estimation</a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/privacy/>Privacy Policy</a>
&#183;
<a href=/terms/>Legal details</a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/vendor-bundle.min.b73dfaac3b6499dc997741748a7c3fe2.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=/en/js/wowchemy.min.0a44fc41442b2268d9632acb006be76d.js></script></body></html>