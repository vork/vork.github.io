<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.6"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=/css/vendor-bundle.min.047268c6dd09ad74ba54a0ba71837064.css media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href=/css/wowchemy.4228702cea630023ae1883491e9ef88b.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=google-site-verification content="S4KoopgNiTG4YgetELfTyLoFaDS9bHbC3gJBOdfft3o"><meta name=msvalidate.01 content="2625B23426FAE2D4025878BAF046F9A0"><meta name=author content="Mark Boss"><meta name=description content="Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art."><link rel=alternate hreflang=en-us href=https://markboss.me/publication/2021-neural-pil/><link rel=canonical href=https://markboss.me/publication/2021-neural-pil/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#009688"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:site" content="@markb_boss"><meta property="twitter:creator" content="@markb_boss"><meta property="twitter:image" content="https://markboss.me/publication/2021-neural-pil/featured.jpg"><meta property="og:type" content="article"><meta property="og:site_name" content="Mark Boss"><meta property="og:url" content="https://markboss.me/publication/2021-neural-pil/"><meta property="og:title" content="Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition | Mark Boss"><meta property="og:description" content="Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art."><meta property="og:image" content="https://markboss.me/publication/2021-neural-pil/featured.jpg"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2021-10-19T00:00:00+00:00"><meta property="article:modified_time" content="2021-10-19T00:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://markboss.me/publication/2021-neural-pil/"},"headline":"Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition","image":["https://markboss.me/publication/2021-neural-pil/featured.jpg"],"datePublished":"2021-10-19T00:00:00Z","dateModified":"2021-10-19T00:00:00Z","author":{"@type":"Person","name":"Mark Boss"},"publisher":{"@type":"Organization","name":"Mark Boss","logo":{"@type":"ImageObject","url":"https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_192x192_fill_lanczos_center_3.png"}},"description":"Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art."}</script><title>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition | Mark Boss</title>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css crossorigin=anonymous media=print onload='this.media="all"' integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw=="></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=6add6d439d4627f4ea9c14675576eb6e><script src=/js/wowchemy-init.min.e1d05065ea0d70e40dcd8bf319bec2e9.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Mark Boss</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Mark Boss</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/files/cv.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</h1><div class=article-metadata><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/raphael-braun/>Raphael Braun</a></span>, <span><a href=/author/ce-liu/>Ce Liu</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div><span class=article-date>October, 2021</span></div><div class="btn-links mb-3"><a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/2021-neural-pil/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2110.14373 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header" href=https://youtu.be/p5cKaNwVp4M target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/cgtuebingen/Neural-PIL target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:720px;max-height:194px><div style=position:relative><img src=/publication/2021-neural-pil/featured_hu557982f4a73d07f363dd1cf0452a897a_50708_60bdd33be098519e4c71e390d81ee975.webp width=720 height=194 alt="Overview of the method. Neural-PIL decomposes a scene from multiple input images into a neural volume with explicit BRDFs. As this problem is highly underconstrained Neural-PIL uses a neural illumination model and network which enforces a smooth BRDF embedding." class=featured-image></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#paper-conference>Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Publication</div><div class="col-12 col-md-9">In <em>Neural Information Processing Systems</em></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe src=https://www.youtube.com/embed/p5cKaNwVp4M style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe></div><h3 id=introduction>Introduction</h3><p>Besides the general <a href=https://dellaert.github.io/NeRF/ target=_blank rel=noopener>NeRF Explosion</a> of 2020, a subfield of introducing explicit material representations in to neural volume representation emerged with papers such as <a href=/publication/2021-nerd/>NeRD</a>, <a href=https://pratulsrinivasan.github.io/nerv/ target=_blank rel=noopener>NeRV</a>, <a href=https://arxiv.org/abs/2008.03824 target=_blank rel=noopener>Neural Reflectance Fields for Appearance Acquisition</a>, <a href=https://kai-46.github.io/PhySG-website/ target=_blank rel=noopener>PhySG</a> or <a href=https://people.csail.mit.edu/xiuming/projects/nerfactor/ target=_blank rel=noopener>NeRFactor</a>. The way illumination is represented varies drastically between the methods. Either the methods focus on single-point lights such as in <a href=https://arxiv.org/abs/2008.03824 target=_blank rel=noopener>Neural Reflectance Fields for Appearance Acquisition</a>, it is assumed to be known (NeRV), it is extracted from a trained NeRF as an illumination map (NeRFactor), or it is represented as Spherical Gaussians (NeRD and PhySG). It is also worth pointing out that nearly all methods focus on a single illumination per scene, except NeRD.</p><p>While NeRD enabled decomposition from multiple views under different illumination, SGs only allowed for rather diffuse illuminations. Inspired from <a href=https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf target=_blank rel=noopener>Pre-integrated Lighting</a> from real-time rendering, we transfer this concept to a neural network, which handles the integration and can represent illuminations from a manifold of natural illuminations.</p><h2 id=method>Method</h2><figure id=figure-the-neural-pil-architecture><div class="d-flex justify-content-center"><div class=w-100><img alt="The Neural-PIL architecture." srcset="/publication/2021-neural-pil/NeuralPIL_hu4172eccdb630b879972ccb5c83230ade_17271_f65ed7f0eae768f8d2fe04858fedb038.webp 400w,
/publication/2021-neural-pil/NeuralPIL_hu4172eccdb630b879972ccb5c83230ade_17271_c8d406d520e0d639062f4ba09d83e4b1.webp 760w,
/publication/2021-neural-pil/NeuralPIL_hu4172eccdb630b879972ccb5c83230ade_17271_1200x1200_fit_q75_h2_lanczos.webp 1200w" src=/publication/2021-neural-pil/NeuralPIL_hu4172eccdb630b879972ccb5c83230ade_17271_f65ed7f0eae768f8d2fe04858fedb038.webp width=375 height=253 loading=lazy data-zoomable></div></div><figcaption data-pre=Figure&nbsp; data-post=:&nbsp; class=numbered>The Neural-PIL architecture.</figcaption></figure><p>In <a href=#figure-the-neural-pil-architecture><strong>FIGURE 1</strong></a> visualizes the Neural-PIL architecture, which is inspired by <a href=https://marcoamonteiro.github.io/pi-GAN-website/ target=_blank rel=noopener>pi-GAN</a>. As seen, the mapping networks are used on the embedding $z^l$, which describes the general content of the environment map and the roughness $b_r$, which defines how rough and therefore how blurry the environment should be.</p><figure id=figure-pre-integrated-lighting-visualzed><div class="d-flex justify-content-center"><div class=w-100><img alt="Pre-integrated Lighting visualzed." srcset="/publication/2021-neural-pil/PreintegratedIllumViz_hu8b613da489dbe18525fd7f969d376644_20971_9b482253ec45a6df9381bef693190cf0.webp 400w,
/publication/2021-neural-pil/PreintegratedIllumViz_hu8b613da489dbe18525fd7f969d376644_20971_71abc23863cc4b37e7472a0d5c76b9fa.webp 760w,
/publication/2021-neural-pil/PreintegratedIllumViz_hu8b613da489dbe18525fd7f969d376644_20971_1200x1200_fit_q75_h2_lanczos.webp 1200w" src=/publication/2021-neural-pil/PreintegratedIllumViz_hu8b613da489dbe18525fd7f969d376644_20971_9b482253ec45a6df9381bef693190cf0.webp width=760 height=108 loading=lazy data-zoomable></div></div><figcaption data-pre=Figure&nbsp; data-post=:&nbsp; class=numbered>Pre-integrated Lighting visualzed.</figcaption></figure><p>Visually this can be seen in <a href=#figure-pre-integrated-lighting-visualzed><strong>FIGURE 2</strong></a>. If the BRDF, shown on the left for each pair, becomes rougher, the illuminations from a larger area get integrated. The result is a blurrier environment map.</p><p>As a joint decomposition of illumination, shape, and appearance is a challenging, ill-posed task, we introduce priors to the BRDF and illumination. The illumination should only lie on a smooth manifold of natural illumination and the BRDF on possible materials. Here, we introduce a Smooth Manifold Auto-Encoder (SMAE).</p><figure id=figure-smooth-manifold-auto-encoder><div class="d-flex justify-content-center"><div class=w-100><img alt=Smooth-Manifold-Auto-Encoder. srcset="/publication/2021-neural-pil/SMAE_hu6144a3c158b55ef5327a5cd6fa3058f9_21047_712e77003ea0bdb06796212f28cc6030.webp 400w,
/publication/2021-neural-pil/SMAE_hu6144a3c158b55ef5327a5cd6fa3058f9_21047_ee450154c756a0c55d12b6eab27b418a.webp 760w,
/publication/2021-neural-pil/SMAE_hu6144a3c158b55ef5327a5cd6fa3058f9_21047_1200x1200_fit_q75_h2_lanczos.webp 1200w" src=/publication/2021-neural-pil/SMAE_hu6144a3c158b55ef5327a5cd6fa3058f9_21047_712e77003ea0bdb06796212f28cc6030.webp width=408 height=249 loading=lazy data-zoomable></div></div><figcaption data-pre=Figure&nbsp; data-post=:&nbsp; class=numbered>Smooth-Manifold-Auto-Encoder.</figcaption></figure><p>Inspired by Berthelot et al. - <a href=https://arxiv.org/abs/1807.07543 target=_blank rel=noopener>Understanding and Improving Interpolation in Autoencoders via an Adversarial Regularizer</a>, we introduce the interpolation in latent space during training, we further introduce three additional losses which further aid in a smooth manifold formation. The smoothness loss encourages a smooth gradient w.r.t. to the interpolation factor and therefore achieves a smooth interpolation between two points in the latent space. The cyclic loss enforces that the encoder and decoder perform the same step by re-encoding the decoded interpolated embeddings and ensuring the re-encoded latent vectors are the same as the initial ones. Lastly, we add a discriminator trained on the examples from the dataset as real ones and the interpolated ones as fake and try to fool it with our interpolated embeddings. With these three losses, a smooth latent space is formed, which allows for an easy introduction in our framework, where the corresponding networks are frozen, and only the latent space is optimized.</p></div><div class=article-tags><a class="badge badge-light" href=/tag/material-acquisition/>Material Acquisition</a>
<a class="badge badge-light" href=/tag/shape/>Shape</a>
<a class="badge badge-light" href=/tag/machine-learning/>Machine Learning</a>
<a class="badge badge-light" href=/tag/optimization/>Optimization</a>
<a class="badge badge-light" href=/tag/svbrdf/>SVBRDF</a>
<a class="badge badge-light" href=/tag/neural-rendering/>Neural Rendering</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fmarkboss.me%2Fpublication%2F2021-neural-pil%2F&amp;text=Neural-PIL%3A+Neural+Pre-Integrated+Lighting+for+Reflectance+Decomposition" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Fmarkboss.me%2Fpublication%2F2021-neural-pil%2F&amp;t=Neural-PIL%3A+Neural+Pre-Integrated+Lighting+for+Reflectance+Decomposition" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=Neural-PIL%3A%20Neural%20Pre-Integrated%20Lighting%20for%20Reflectance%20Decomposition&amp;body=https%3A%2F%2Fmarkboss.me%2Fpublication%2F2021-neural-pil%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fmarkboss.me%2Fpublication%2F2021-neural-pil%2F&amp;title=Neural-PIL%3A+Neural+Pre-Integrated+Lighting+for+Reflectance+Decomposition" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://web.whatsapp.com/send?text=Neural-PIL%3A+Neural+Pre-Integrated+Lighting+for+Reflectance+Decomposition%20https%3A%2F%2Fmarkboss.me%2Fpublication%2F2021-neural-pil%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Fmarkboss.me%2Fpublication%2F2021-neural-pil%2F&amp;title=Neural-PIL%3A+Neural+Pre-Integrated+Lighting+for+Reflectance+Decomposition" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div><div class="media author-card content-widget-hr"><a href=https://markboss.me/><img class="avatar mr-3 avatar-circle" src=/author/mark-boss/avatar_hu8228efeb083742449721d94a9befbadd_1942861_270x270_fill_q75_lanczos_center.jpg alt="Mark Boss"></a><div class=media-body><h5 class=card-title><a href=https://markboss.me/>Mark Boss</a></h5><h6 class=card-subtitle>Research Scientist</h6><p class=card-text>I&rsquo;m a researcher at Stability AI with research interests in the intersection of machine learning and computer graphics.</p><ul class=network-icon aria-hidden=true><li><a href=mailto:hello@markboss.me><i class="fas fa-envelope"></i></a></li><li><a href=https://twitter.com/markb_boss target=_blank rel=noopener><i class="fab fa-twitter"></i></a></li><li><a href="https://scholar.google.com/citations?user=y23cQ6wAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="fas fa-graduation-cap"></i></a></li><li><a href=https://github.com/vork target=_blank rel=noopener><i class="fab fa-github"></i></a></li><li><a href=https://www.linkedin.com/in/markbboss target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://unsplash.com/@vork target=_blank rel=noopener><i class="fab fa-unsplash"></i></a></li></ul></div></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/privacy/>Privacy Policy</a>
&#183;
<a href=/terms/>Legal details</a></p><p class="powered-by copyright-license-text">© 2024 Mark Boss. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> — the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.938a3a7554cd9f6602290411f64d2617.js></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.62586ca65ca61821fe707eb9fa6268b7.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9137013a66774049159934c29c3f0205.js type=module></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin=anonymous></script></body></html>