[{"authors":["admin"],"categories":null,"content":"I am a Ph.D. student under the supervision of Prof. Hendrik P. A. Lensch in the Computer Graphics Group at the University of Tübingen. My research interests lie at the intersection of machine learning and computer graphics. The main research question is how to perform inverse rendering on sparse and casual captured images. Here, I primarily focus on enabling efficient material appearance acquisition.\n Download my CV ","date":1606435200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1606435200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://markboss.me/author/mark-boss/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mark-boss/","section":"authors","summary":"I am a Ph.D. student under the supervision of Prof. Hendrik P. A. Lensch in the Computer Graphics Group at the University of Tübingen. My research interests lie at the intersection of machine learning and computer graphics. The main research question is how to perform inverse rendering on sparse and casual captured images. Here, I primarily focus on enabling efficient material appearance acquisition.\n Download my CV ","tags":null,"title":"Mark Boss","type":"authors"},{"authors":null,"categories":null,"content":"","date":1624838400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1624838400,"objectID":"ca2aaae623c7a0530f021ca2ffd27321","permalink":"https://markboss.me/project/farrow-and-ball/","publishdate":"2021-06-28T00:00:00Z","relpermalink":"/project/farrow-and-ball/","section":"project","summary":"A set of British paint manufacturer Farrow \u0026 Ball inspired color maps for matplotlib. The library is also available on [pypi](https://pypi.org/project/farrow-and-ball/). The maps are sorted in categories for different plotting needs (Divergent, Spectral, Base Colors, Misc).","tags":["Python","Matplotlib","Open Source"],"title":"farrow-and-ball","type":"project"},{"authors":null,"categories":null,"content":"","date":1607252243,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607252243,"objectID":"9cb88f7fd23e1f438ba83fc5b86a6d21","permalink":"https://markboss.me/news/arxiv20-nerd/","publishdate":"2020-12-06T11:57:23+01:00","relpermalink":"/news/arxiv20-nerd/","section":"news","summary":"**[ArXiv](https://arxiv.org/abs/2012.03918)** submission and **[Project page](/publication/2021-nerd/)** online","tags":null,"title":"NeRD: Neural Reflectance Decomposition from Image Collections","type":"news"},{"authors":[],"categories":[],"content":"A bidirectional reflectance distribution function (BRDF) is a function which defines how incoming light $\\omega_i$ is reflected to every outgoing direction $\\omega_o$ on the hemisphere $f_r(\\omega_i, \\omega_o)$. A BRDF can be measured by capturing a surface from various known view and light positions. The information can then be stored in a texture where the x and y coordinates represent the corresponding view and light direction. This is mostly only done for materials that do not vary over the surface due to the information density. Therefore, often analytical BRDF models are used. Parameters are then used to build a function that can be queried for all incoming and outgoing directions. One popular model is the Cook-Torrance model, which parametrizes the BRDF with a diffuse and specular color plus a roughness value. The model is split into a diffuse and specular lobe. Below is an interactive visualizer, where you can change the diffuse, specular, and roughness parameters.\n  Interpolating between random BRDFs is also quite soothing:\n  If you want to use this interactive visualizer for teaching, feel free to use it: link.\n","date":1606815159,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606815159,"objectID":"f71f70059247e8ea0ed80da74f8ecfe5","permalink":"https://markboss.me/project/web_brdf_viz/","publishdate":"2020-12-01T10:32:39+01:00","relpermalink":"/project/web_brdf_viz/","section":"project","summary":"The bidirectional reflectance distribution function (BRDF) is a function that defines how incoming light is reflected outward. This web-based visualizer uses the Cook-Torrance model and shows how the material looks on a sphere, and simultaneously displays its evaluated BRDF. Especially the different reflective behavior of specular and diffuse materials are easily visible.","tags":["Teaching"],"title":"Online BRDF Visualization","type":"project"},{"authors":["Mark Boss","Raphael Braun","Varun Jampani","Jonathan T. Barron","Ce Liu","Hendrik P. A. Lensch"],"categories":null,"content":"   Introduction NeRD is a novel method that can decompose image collections from multiple views taken under varying or fixed illumination conditions. The object can be rotated, or the camera can turn around the object. The result is a neural volume with an explicit representation of the appearance and illumination in the form of the BRDF and Spherical Gaussian (SG) environment illumination.\nThe method is based on the general structure of NeRF. However, NeRF encodes the scene to an implicit BRDF representation where a Multi-Layer-Perceptron (MLP) is queried for outgoing view directions at every point. Extracting information from NeRF is therefore not easily done, and the inference time for novel views takes around 30 seconds. Also, NeRF is not capable of relighting an object under any illumination. By introducing physically-based representations for lighting and appearance, NeRD can relighting an object, and information can be extracted from the neural volume. After our extraction process, the result is a regular texture mesh that can be rendered in real-time. See our results where we provide a web-based interactive renderer.\nMethod Decomposing the scene requires that the integral over the hemisphere from the rendering equation is decomposed into its parts. Here, we use a simplified version without self-emittance. $$L_o(x,\\omega_o) = \\int_\\Omega L_i(x,\\omega_i) f_r(x,\\omega_i,\\omega_o) (\\omega_i \\cdot n) d\\omega_i$$ Here, $L_o$ is the outgoing radiance for a point $x$ in the direction $\\omega_o$. This radiance is calculated by integrating all influences over the hemisphere $\\Omega$, which are based on the incoming light $L_i$ for each direction $\\omega_i$. The surface behavior is expressed as the BRDF $f_r$, which describes how incoming light $\\omega_i$ is directed to the outgoing direction $\\omega_o$. Lastly, a cosine term is used $(\\omega_i \\cdot n)$, which reduces the received light based on the angle towards the light source.\nThe inverse of this integral is highly ambiguous, and we use several approximations to solve it. We do not use any interreflections or shadowing, which means that we do not compute the incoming radiance recursively. Additionally, our illumination is expressed as SG, which reduces a full continuous integral to - in our case - 24 evaluation of the environment SGs.\n Steps of the query process. In a) the volume is constructed by tracing rays from each camera into the scene. Then samples are placed along with the rays in b), and based on the density at each sampling point, additional samples are placed in c). The samples are then evaluated into a BRDF, which is re-rendered using the jointly optimized illumination in d).  Inspired by NeRF the method uses two MLPs, which encode the each position in the volume $\\textbf{x} = (x,y,z)$ to a volume density $\\sigma$ and a color or BRDF parameters. Figure 1 shows an overview of this optimization process.\n Overview of the sampling network.   Overview of the decomposition network.  --   -- Results  Click the images for an interactive 3D visualization.   Real-world    Real-world (Preliminary in the wild) The images from the Statue of Liberty are collected from Flickr, Unsplash, Youtube and Vimeo videos. In total about 120 images are used for training from various phones, cameras and drones. Overall even the COLMAP registration is not perfect due to the simplistic shared camera model.\n  Synthetic Examples     ","date":1606435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606435200,"objectID":"b3f35247536c5e8294a8640a508e3b70","permalink":"https://markboss.me/publication/2021-nerd/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/2021-nerd/","section":"publication","summary":"Decomposing a scene into its shape, reflectance, and illumination is a challenging but essential problem in computer vision and graphics. This problem is inherently more challenging when the illumination is not a single light source under laboratory conditions but is instead an unconstrained environmental illumination. Though recent work has shown that implicit representations can be used to model the radiance field of an object, these techniques only enable view synthesis and not relighting. Additionally, evaluating these radiance fields is resource and time-intensive. By decomposing a scene into explicit representations, any rendering framework can be leveraged to generate novel views under any illumination in real-time. NeRD is a method that achieves this decomposition by introducing physically-based rendering to neural radiance fields. Even challenging non-Lambertian reflectances, complex geometry, and unknown illumination can be decomposed to high-quality models.","tags":["Material Acquisition","Shape","Machine Learning","Optimization","SVBRDF","Neural Rendering"],"title":"NeRD: Neural Reflectance Decomposition from Image Collections","type":"publication"},{"authors":null,"categories":null,"content":"","date":1599782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599782400,"objectID":"30952f371f78725639cac67837164e65","permalink":"https://markboss.me/news/cvpr20-code/","publishdate":"2020-09-11T00:00:00Z","relpermalink":"/news/cvpr20-code/","section":"news","summary":"Source code and dataset released: **[Github](https://github.com/NVlabs/two-shot-brdf-shape)**","tags":null,"title":"Two-shot Spatially-varying BRDF and Shape Estimation","type":"news"},{"authors":["Mark Boss","Varun Jampani","Kihwan Kim","Hendrik P. A. Lensch","Jan Kautz"],"categories":null,"content":"   Results  Click the images for an interactive 3D visualization.   Aksoy et al. - A Dataset of Flash and Ambient Illumination Pairs from the Crowd                  Real-world Examples      Synthetic Examples      Copyright This material is posted here with permission of the IEEE. Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to pubs-permissions@ieee.org.\n","date":1592265600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592265600,"objectID":"876f8c22bd2dde8478d06100c11e546b","permalink":"https://markboss.me/publication/cvpr20-two-shot-brdf/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/cvpr20-two-shot-brdf/","section":"publication","summary":"Capturing the shape and spatially-varying appearance (SVBRDF) of an object from images is a challenging task that has applications in both computer vision and graphics. Traditional optimization-based approaches often need a large number of images taken from multiple views in a controlled environment. Newer deep learning-based approaches require only a few input images, but the reconstruction quality is not on par with optimization techniques. We propose a novel deep learning architecture with a stage-wise estimation of shape and SVBRDF. The previous predictions guide each estimation, and a joint refinement network later refines both SVBRDF and shape. We follow a practical mobile image capture setting and use unaligned two-shot flash and no-flash images as input. Both our two-shot image capture and network inference can run on mobile hardware. We also create a large-scale synthetic training dataset with domain-randomized geometry and realistic materials. Extensive experiments on both synthetic and real-world datasets show that our network trained on a synthetic dataset can generalize well to real-world images. Comparisons with recent approaches demonstrate the superior performance of the proposed approach.","tags":["Material Acquisition","Machine Learning","Two-Shot","Shape","Depth Map","SVBRDF"],"title":"Two-shot Spatially-varying BRDF and Shape Estimation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1582502400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1582502400,"objectID":"6082eb6237dcf86bdb87a6e456af7380","permalink":"https://markboss.me/news/cvpr20-accept/","publishdate":"2020-02-24T00:00:00Z","relpermalink":"/news/cvpr20-accept/","section":"news","summary":"Accepted for a CVPR 2020 Poster Presentation","tags":null,"title":"Two-shot Spatially-varying BRDF and Shape Estimation","type":"news"},{"authors":null,"categories":null,"content":"","date":1577491200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577491200,"objectID":"d648370abc4a7f8a9867bdf500fbd632","permalink":"https://markboss.me/project/infomark/","publishdate":"2019-12-28T00:00:00Z","relpermalink":"/project/infomark/","section":"project","summary":"A free, scalable, modern and open source solution for programming lectures supporting auto-testing/grading of programming assignments scaling to thousands of students and several courses.","tags":["Teaching"],"title":"Infomark","type":"project"},{"authors":["Mark Boss","Hendrik P. A. Lensch"],"categories":null,"content":"","date":1570752e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570752e3,"objectID":"b5e50bbae57ddc67784104b3cac55f18","permalink":"https://markboss.me/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/","section":"publication","summary":"Creating plausible surfaces is an essential component in achieving a high degree of realism in rendering. To relieve artists, who create these surfaces in a time-consuming, manual process, automated retrieval of the spatially-varying Bidirectional Reflectance Distribution Function (SVBRDF) from a single mobile phone image is desirable. By leveraging a deep neural network, this casual capturing method can be achieved. The trained network can estimate per pixel normal, base color, metallic and roughness parameters from the Disney BRDF. The input image is taken with a mobile phone lit by the camera flash. The network is trained to compensate for environment lighting and thus learned to reduce artifacts introduced by other light sources. These losses contain a multi-scale discriminator with an additional perceptual loss, a rendering loss using a differentiable renderer, and a parameter loss. Besides the local precision, this loss formulation generates material texture maps which are globally more consistent. The network is set up as a generator network trained in an adversarial fashion to ensure that only plausible maps are produced. The estimated parameters not only reproduce the material faithfully in rendering but capture the style of hand-authored materials due to the more global loss terms compared to previous works without requiring additional post-processing. Both the resolution and the quality is improved.","tags":["Material Acquisition","Machine Learning","Single-Shot","Flat Surface","SVBRDF"],"title":"Single Image BRDF Parameter Estimation with a Conditional Adversarial Network","type":"publication"},{"authors":["Mark Boss","Fabian Groh","Sebastian Herholz","Hendrik P. A. Lensch"],"categories":null,"content":"","date":1530403200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530403200,"objectID":"2c17505f22b1b0ca69d3e04d1557f1d5","permalink":"https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/deep-dual-loss-brdf-parameter-estimation/","section":"publication","summary":"Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. We propose a method which utilizes an encoder-decoder Convolutional Neural Network (CNN) to extract parameters for the Bidirectional Reflectance Distribution Function (BRDF) automatically from a sparse sample set. This is done by implementing a differentiable renderer, which allows for a loss backpropagation of rendered images. This photometric loss is essential because defining a numerical BRDF distance metric is difficult. A second loss is added, which compares the parameters maps directly. Therefore, the statistical properties of the BRDF model are learned, which reduces artifacts in the predicted parameters. This dual loss principal improves the result of the network significantly. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF (SVBRDF) parameters with a sufficiently high resolution for intended real-world usage. The capture process for materials only requires five known light positions with a fixed camera position. This reduces the scanning time drastically, and a material sample can be obtained in seconds with an automated system.","tags":["Material Acquisition","Machine Learning","Multi-Shot","Flat Surface","SVBRDF"],"title":"Deep Dual Loss BRDF Parameter Estimation","type":"publication"},{"authors":null,"categories":null,"content":"Legal Disclosure Information in accordance with Section 5 TMG\nMark Boss\nBismarckstr. 114\n72072 Tübingen\nContact Information E-Mail: markboss@mailbox.org\nInternet address: markboss.me\nDisclaimer Accountability for content The contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this matter, please note that we are not obliged to monitor the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per §§ 8 to 10 of the Telemedia Act (TMG).\nAccountability for links Responsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately.\nCopyright Our web pages and their contents are subject to German copyright law. Unless expressly permitted by law, every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are only allowed for private use. The materials from these pages are copyrighted and any unauthorized use may violate copyright laws.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"9b10c1f64082d3869fd4cb1f85809430","permalink":"https://markboss.me/terms/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/terms/","section":"","summary":"Legal Disclosure Information in accordance with Section 5 TMG\nMark Boss\nBismarckstr. 114\n72072 Tübingen\nContact Information E-Mail: markboss@mailbox.org\nInternet address: markboss.me\nDisclaimer Accountability for content The contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this matter, please note that we are not obliged to monitor the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity.","tags":null,"title":"Legal details","type":"page"},{"authors":null,"categories":null,"content":"Your privacy is important to us. It is Mark Boss' policy to respect your privacy regarding any information we may collect from you across our website, https://www.markboss.me, and other sites we own and operate.\nWe only ask for personal information when we truly need it to provide a service to you. We collect it by fair and lawful means, with your knowledge and consent. We also let you know why we’re collecting it and how it will be used.\nWe only retain collected information for as long as necessary to provide you with your requested service. What data we store, we’ll protect within commercially acceptable means to prevent loss and theft, as well as unauthorized access, disclosure, copying, use or modification.\nWe don’t share any personally identifying information publicly or with third-parties, except when required to by law.\nOur website may link to external sites that are not operated by us. Please be aware that we have no control over the content and practices of these sites, and cannot accept responsibility or liability for their respective privacy policies.\nYou are free to refuse our request for your personal information, with the understanding that we may be unable to provide you with some of your desired services.\nYour continued use of our website will be regarded as acceptance of our practices around privacy and personal information. If you have any questions about how we handle user data and personal information, feel free to contact us.\nThis policy is effective as of 1 April 2020.\n","date":1530140400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1530140400,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"https://markboss.me/privacy/","publishdate":"2018-06-28T00:00:00+01:00","relpermalink":"/privacy/","section":"","summary":"Your privacy is important to us. It is Mark Boss' policy to respect your privacy regarding any information we may collect from you across our website, https://www.markboss.me, and other sites we own and operate.\nWe only ask for personal information when we truly need it to provide a service to you. We collect it by fair and lawful means, with your knowledge and consent. We also let you know why we’re collecting it and how it will be used.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":["Mark Boss","Hendrik P. A. Lensch"],"categories":null,"content":"","date":1525132800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525132800,"objectID":"3a9afb08e7d0d94f6bb3e8fb2337a5ad","permalink":"https://markboss.me/publication/master_thesis/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/master_thesis/","section":"publication","summary":"The behavior of surfaces is an essential field in computer games and movies. An exact representation of a real-world surface allows for a higher degree of realism. Capturing or artistically creating these materials is a time-consuming process. Thus, in this thesis a method which utilizes an encoder-decoder Convolutional Neural Networks (CNN) to extract information of the Bidirectional Reflectance Distribution Function (BRDF) automatically is proposed. Opposed to previous means this method retrieves information of the whole surface as spatially varying BRDF-parameters with a sufficiently high resolution for real-world usage. The capture process for materials only requires five known light positions with a fixed camera position and thus can be acquired even in a mobile setup. This reduces the scanning time drastically and a material sample can be obtained in seconds with an automated system.","tags":["Material Acquisition","Machine Learning","Multi-Shot","Flat Surface","SVBRDF"],"title":"CNN-based BRDF parameter estimation","type":"publication"}]