<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.4.0 for Hugo"><meta name=google-site-verification content="S4KoopgNiTG4YgetELfTyLoFaDS9bHbC3gJBOdfft3o"><meta name=msvalidate.01 content="2625B23426FAE2D4025878BAF046F9A0"><meta name=author content="Mark Boss"><meta name=description content="Personal Research Website of Mark Boss"><link rel=alternate hreflang=en-us href=https://markboss.me/><meta name=theme-color content="#009688"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=/css/wowchemy.7c5470f4eb8eccc945078663ffb75c1f.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Mark Boss"><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hube1743d0a4940c76c300ec8349475861_6659_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://markboss.me/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@markb_boss"><meta property="twitter:creator" content="@markb_boss"><meta property="og:site_name" content="Mark Boss"><meta property="og:url" content="https://markboss.me/"><meta property="og:title" content="Mark Boss"><meta property="og:description" content="Personal Research Website of Mark Boss"><meta property="og:image" content="https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://markboss.me/media/icon_hube1743d0a4940c76c300ec8349475861_6659_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2022-10-01T18:24:54+02:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://markboss.me/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://markboss.me/"}</script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=all onload='this.media="all"'><title>Mark Boss</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.9c53337151330e4f750895b53468cbe3.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Mark Boss</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Mark Boss</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#posts data-target=#posts><span>Posts</span></a></li><li class=nav-item><a class=nav-link href=/#talks data-target=#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience data-target=#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/files/cv.pdf><span>CV</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" width=270 height=270 src=/author/mark-boss/avatar_hu8228efeb083742449721d94a9befbadd_1942861_270x270_fill_q75_lanczos_center.jpg alt="Mark Boss"><div class=portrait-title><h2>Mark Boss</h2><h3>Research Scientist</h3><h3><a href=https://unity.com target=_blank rel=noopener><span>Unity Technologies</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=mailto:hello@markboss.me aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href=https://twitter.com/markb_boss target=_blank rel=noopener aria-label=twitter><i class="fab fa-twitter big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=y23cQ6wAAAAJ&hl=en" target=_blank rel=noopener aria-label=graduation-cap><i class="fas fa-graduation-cap big-icon"></i></a></li><li><a href=https://github.com/vork target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/markbboss target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>Biography</h1><div class=article-style><p>Mark Boss is a researcher at Unity Technologies. Before that, he was a Ph.D. student at the University of Tübingen in the computer graphics group of Prof. Hendrik Lensch. His research interests lie at the intersection of machine learning and computer graphics, with the main focus on inferring physical properties (shape, material, illumination, etc.) from images.</p><p>If you are interested in a research collaboration, please drop me a <a href=mailto:hello@markboss.me> 
<i class="fas fa-envelope pr-1 fa-fw"></i> mail</a> with your CV.</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Machine Learning</li><li>Computer Graphics</li><li>Inverse Rendering</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MSc in Computer Science, 2018</p><p class=institution>University of Tübingen</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>BSc in Computer Science, 2016</p><p class=institution>Osnabrück University of Applied Sciences</p></div></li></ul></div></div></div></div></div></section><section id=news class="home-section wg-github-vork-news"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>News</h1></div><div class="col-12 col-lg-8"><div class=view-list-item><span>SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections</span><div class=article-metadata><span>15 Sep 2022 - Accepted at NeurIPS 2022.</span></div></div><div class=view-list-item><span>An open-source smartphone app for the quantitative evaluation of thin-layer chromatographic analyses in medicine quality screening</span><div class=article-metadata><span>04 Aug 2022 - <strong><a href=https://doi.org/10.1038/s41598-022-17527-y target=_blank rel=noopener>Scientific Report</a></strong> article and <strong><a href=/publication/2022-tlcyzer/>Project page</a></strong> online</span></div></div><div class=view-list-item><span>SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections</span><div class=article-metadata><span>31 May 2022 - <strong><a href=https://arxiv.org/abs/2205.15768 target=_blank rel=noopener>ArXiv</a></strong> submission and <strong><a href=/publication/2022-samurai/>Project page</a></strong> online</span></div></div><div class=view-list-item><span>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</span><div class=article-metadata><span>19 Oct 2021 - Accepted at NeurIPS 2021 Poster Presentation, <strong><a href=https://arxiv.org/abs/2110.14373 target=_blank rel=noopener>arXiv</a></strong> and <strong><a href=/publication/2021-neural-pil/>Project page</a></strong> online</span></div></div><div class=view-list-item><span>NeRD: Neural Reflectance Decomposition from Image Collections</span><div class=article-metadata><span>18 Aug 2021 - Accepted for a ICCV 2021 Poster Presentation</span></div></div><div class=see-all><a href=/news/>See all
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=posts class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent Posts</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/nerf_at_eccv22/>NeRF at ECCV 2022</a></div><a href=/post/nerf_at_eccv22/ class=summary-link><div class=article-style>I recently went through the the provisional programm of ECCV 2022. After my last post on &ldquo;NeRF at NeurIPS&rdquo; got such great feedback, and I anyway compiled a list of all NeRFy things, I decided to do it all again.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Oct 1, 2022</span>
<span class=middot-divider></span>
<span class=article-reading-time>11 min read</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/nerf/>NeRF</a>, <a href=/category/literature-review/>Literature Review</a></span></div></div></div><div class=ml-3></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/post/nerf_at_neurips22/>NeRF at NeurIPS 2022</a></div><a href=/post/nerf_at_neurips22/ class=summary-link><div class=article-style>Inspired by Frank Dellaert and his excellent series on the original NeRF Explosion and the following ICCV/CVPR conference gatherings, I decided to look into creating a NeurIPS 22 rundown myself.</div></a><div class="stream-meta article-metadata"><div class=article-metadata><span class=article-date>Last updated on
Sep 30, 2022</span>
<span class=middot-divider></span>
<span class=article-reading-time>8 min read</span>
<span class=middot-divider></span>
<span class=article-categories><i class="fas fa-folder mr-1"></i><a href=/category/nerf/>NeRF</a>, <a href=/category/literature-review/>Literature Review</a></span></div></div></div><div class=ml-3></div></div></div></div></div></section><section id=talks class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Recent & Upcoming Talks</h1></div><div class="col-12 col-lg-8"><div class="view-list view-list-item"><i class="far fa-calendar-alt pub-icon" aria-hidden=true></i>
<a href=/talk/neural-reflectance-decomposition/>Neural Reflectance Decomposition</a><div class=article-metadata><span>Jul 26, 2022 10:00 AM &mdash; 11:00 AM</span>
<span class=middot-divider></span>
<span>Adobe Research</span></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/talks/adobe_talk target=_blank rel=noopener>Slides</a></div></div></div></div></div></section><section id=publications class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022-samurai/>SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections</a></div><a href=/publication/2022-samurai/ class=summary-link><div class=article-style>Inverse rendering of an object under entirely unknown capture conditions is a fundamental challenge in computer vision and graphics. …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/andreas-engelhardt/>Andreas Engelhardt</a></span>, <span><a href=/author/abhishek-kar/>Abhishek Kar</a></span>, <span><a href=/author/yuanzhen-li/>Yuanzhen Li</a></span>, <span><a href=/author/deqing-sun/>Deqing Sun</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022-samurai/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/talks/samurai_neurips/ target=_blank rel=noopener>Slides</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2205.15768 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/LlYuGDjXp-8 target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a></div></div><div class=ml-3><a href=/publication/2022-samurai/><img src=/publication/2022-samurai/featured_hueebc0576a6a37e9404d18d9e27e81796_130114_150x0_resize_q75_h2_lanczos.webp height=55 width=150 alt="SAMURAI: Shape And Material from Unconstrained Real-world Arbitrary Image collections" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2022-tlcyzer/>An open-source smartphone app for the quantitative evaluation of thin-layer chromatographic analyses in medicine quality screening</a></div><a href=/publication/2022-tlcyzer/ class=summary-link><div class=article-style>Substandard and falsified medicines present a serious threat to public health. Simple, low-cost screening tools are important in the …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/cathrin-hauk/>Cathrin Hauk</a></span>, <span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/julia-gabel/>Julia Gabel</a></span>, <span><a href=/author/simon-schafermann/>Simon Schäfermann</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/lutz-heide/>Lutz Heide</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2022-tlcyzer/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/project/tlcyzer/>Project</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.1038/s41598-022-17527-y target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/TLCyzer/tlcyzer target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://tlcyzer.github.io target=_blank rel=noopener><i class="fab fa-browser mr-1"></i>Website</a></div></div><div class=ml-3><a href=/publication/2022-tlcyzer/><img src=/publication/2022-tlcyzer/featured_hu3ded59b12af0e577d0f6c9ba658bb523_562259_150x0_resize_q75_h2_lanczos_3.webp height=128 width=150 alt="An open-source smartphone app for the quantitative evaluation of thin-layer chromatographic analyses in medicine quality screening" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2021-neural-pil/>Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</a></div><a href=/publication/2021-neural-pil/ class=summary-link><div class=article-style>Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/raphael-braun/>Raphael Braun</a></span>, <span><a href=/author/ce-liu/>Ce Liu</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2021-neural-pil/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2110.14373 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/p5cKaNwVp4M target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cgtuebingen/Neural-PIL target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a></div></div><div class=ml-3><a href=/publication/2021-neural-pil/><img src=/publication/2021-neural-pil/featured_hu557982f4a73d07f363dd1cf0452a897a_50708_150x0_resize_q75_h2_lanczos.webp height=40 width=150 alt="Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/2021-nerd/>NeRD: Neural Reflectance Decomposition from Image Collections</a></div><a href=/publication/2021-nerd/ class=summary-link><div class=article-style>Decomposing a scene into its shape, reflectance, and illumination is a challenging but important problem in computer vision and …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/raphael-braun/>Raphael Braun</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/jonathan-t.-barron/>Jonathan T. Barron</a></span>, <span><a href=/author/ce-liu/>Ce Liu</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/2021-nerd/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2012.03918 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/JL-qMTXw9VU target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition#datasets target=_blank rel=noopener><i class="fas fa-database mr-1"></i>Dataset</a></div></div><div class=ml-3><a href=/publication/2021-nerd/><img src=/publication/2021-nerd/featured_hu9ce3dee256724e8b0641511e91e45d8f_249226_150x0_resize_q75_h2_lanczos.webp height=50 width=150 alt="NeRD: Neural Reflectance Decomposition from Image Collections" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/cvpr20-two-shot-brdf/>Two-shot Spatially-varying BRDF and Shape Estimation</a></div><a href=/publication/cvpr20-two-shot-brdf/ class=summary-link><div class=article-style>Capturing the shape and spatially-varying appearance (SVBRDF) of an object from images is a challenging task that has applications in …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/varun-jampani/>Varun Jampani</a></span>, <span><a href=/author/kihwan-kim/>Kihwan Kim</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span>, <span><a href=/author/jan-kautz/>Jan Kautz</a></span></div></div><div class=btn-links><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/cvpr20-two-shot-brdf/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=/files/cvpr20-two-shot-brdf.pdf><i class="fas fa-file-pdf mr-1"></i>Paper + Supplementary</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2004.00403 target=_blank rel=noopener><i class="fas fa-file-pdf mr-1"></i>arXiv</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/CyC6PutoJO8 target=_blank rel=noopener><i class="fab fa-youtube mr-1"></i>Video</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/NVlabs/two-shot-brdf-shape target=_blank rel=noopener><i class="fas fa-code mr-1"></i>Code</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href="https://drive.google.com/file/d/14mou3Va65deimPYE5GtFdK8OS3I0BSzq/view?usp=sharing" target=_blank rel=noopener><i class="fas fa-database mr-1"></i>Dataset</a></div></div><div class=ml-3><a href=/publication/cvpr20-two-shot-brdf/><img src=/publication/cvpr20-two-shot-brdf/featured_hu30910665284931ace4f57faa1e01d828_139209_150x0_resize_q75_h2_lanczos.webp height=65 width=150 alt="Two-shot Spatially-varying BRDF and Shape Estimation" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/>Single Image BRDF Parameter Estimation with a Conditional Adversarial Network</a></div><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/ class=summary-link><div class=article-style>Creating plausible surfaces is an essential component in achieving a high degree of realism in rendering. To relieve artists, who …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1910.05148 target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/><img src=/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/featured_hu30910665284931ace4f57faa1e01d828_105779_150x0_resize_q75_h2_lanczos.webp height=84 width=150 alt="Single Image BRDF Parameter Estimation with a Conditional Adversarial Network" loading=lazy></a></div></div><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/deep-dual-loss-brdf-parameter-estimation/>Deep Dual Loss BRDF Parameter Estimation</a></div><a href=/publication/deep-dual-loss-brdf-parameter-estimation/ class=summary-link><div class=article-style>Surface parameter estimation is an essential field in computer games and movies. An exact representation of a real-world surface allows …</div></a><div class="stream-meta article-metadata"><div><span class=author-highlighted><a href=/author/mark-boss/>Mark Boss</a></span>, <span><a href=/author/fabian-groh/>Fabian Groh</a></span>, <span><a href=/author/sebastian-herholz/>Sebastian Herholz</a></span>, <span><a href=/author/hendrik-p.-a.-lensch/>Hendrik P. A. Lensch</a></span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=/files/deep_dual_loss_brdf_egsr_mam_2018.pdf target=_blank rel=noopener>PDF</a>
<a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/deep-dual-loss-brdf-parameter-estimation/cite.bib>Cite</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://doi.org/10.2312/mam.20181199 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3><a href=/publication/deep-dual-loss-brdf-parameter-estimation/><img src=/publication/deep-dual-loss-brdf-parameter-estimation/featured_hu30910665284931ace4f57faa1e01d828_98512_150x0_resize_q75_h2_lanczos.webp height=73 width=150 alt="Deep Dual Loss BRDF Parameter Estimation" loading=lazy></a></div></div></div></div></div></section><section id=projects class="home-section wg-portfolio"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Projects</h1></div><div class="col-12 col-lg-8"><div class="row js-layout-row"><div class="col-12 isotope-item js-id-Android js-id-Rust js-id-Kotlin js-id-Open-Source"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=https://tlcyzer.github.io target=_blank rel=noopener>TLCyzer</a></div><a href=https://tlcyzer.github.io target=_blank rel=noopener class=summary-link><div class=article-style>TLCyzer is a free and open source smartphone app for the quantitative evaluation of thin-layer chromatographic analyses in medicine quality screening, described and validated in a scientific study.</div></a><div class="stream-meta article-metadata"></div></div><div class=ml-3><a href=https://tlcyzer.github.io target=_blank rel=noopener><img src=/project/tlcyzer/featured_hu3ded59b12af0e577d0f6c9ba658bb523_562259_150x0_resize_q75_h2_lanczos_3.webp height=128 width=150 alt=TLCyzer loading=lazy></a></div></div></div><div class="col-12 isotope-item js-id-Python js-id-Matplotlib js-id-Open-Source"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=https://github.com/vork/farrowandball target=_blank rel=noopener>farrow-and-ball</a></div><a href=https://github.com/vork/farrowandball target=_blank rel=noopener class=summary-link><div class=article-style>A set of British paint manufacturer Farrow & Ball inspired color maps for matplotlib. The maps are sorted in categories for different plotting needs (Divergent, Spectral, Base Colors, Misc).</div></a><div class="stream-meta article-metadata"></div></div><div class=ml-3><a href=https://github.com/vork/farrowandball target=_blank rel=noopener><img src=/project/farrow-and-ball/featured_hu52f801fec1c38d0c2216ad5c035fdf92_3125_150x0_resize_q75_h2_lanczos_3.webp height=119 width=150 alt=farrow-and-ball loading=lazy></a></div></div></div><div class="col-12 isotope-item js-id-Teaching"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/project/web_brdf_viz/>Online BRDF Visualization</a></div><a href=/project/web_brdf_viz/ class=summary-link><div class=article-style>The bidirectional reflectance distribution function (BRDF) is a function that defines how incoming light is reflected outward. This web-based visualizer uses the Cook-Torrance model and shows how the material looks on a sphere, and simultaneously displays its evaluated BRDF. Especially the different reflective behavior of specular and diffuse materials are easily visible.</div></a><div class="stream-meta article-metadata"></div></div><div class=ml-3><a href=/project/web_brdf_viz/><img src=/project/web_brdf_viz/featured_hu42b9ad4760d45bdb9802a75dede8cd48_93350_150x0_resize_q75_h2_lanczos.webp height=114 width=150 alt="Online BRDF Visualization" loading=lazy></a></div></div></div><div class="col-12 isotope-item js-id-Teaching"><div class="media stream-item view-compact"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=https://infomark.org/ target=_blank rel=noopener>Infomark</a></div><a href=https://infomark.org/ target=_blank rel=noopener class=summary-link><div class=article-style>A free, scalable, modern and open source solution for programming lectures supporting auto-testing/grading of programming assignments scaling to thousands of students and several courses.</div></a><div class="stream-meta article-metadata"></div></div><div class=ml-3><a href=https://infomark.org/ target=_blank rel=noopener><img src=/project/infomark/featured_hu7511ac86c67a21fc108a57c999b43d2d_28368_150x0_resize_q75_h2_lanczos_3.webp height=122 width=150 alt=Infomark loading=lazy></a></div></div></div></div></div></div></div></section><section id=experience class="home-section wg-experience"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Experience</h1></div><div class="col-12 col-lg-8"><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class=col>&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border exp-fill">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://unity.com target=_blank rel=noopener><img src=/media/icons/brands/UnityTechnologies.svg width=56px height=56px alt="Unity Technologies" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Senior Research Scientist</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://unity.com target=_blank rel=noopener>Unity Technologies</a></div><div class="text-muted exp-meta">Sep 2022 –
Present
<span class=middot-divider></span>
<span>Germany</span></div></div></div><div class=card-text>Research on object acquisition.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://uni-tuebingen.de/en/ target=_blank rel=noopener><img src=/media/icons/brands/UniTuebingen.svg width=56px height=56px alt="University of Tübingen" loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Ph.D. Student</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://uni-tuebingen.de/en/ target=_blank rel=noopener>University of Tübingen</a></div><div class="text-muted exp-meta">Jun 2018 –
Jun 2022
<span class=middot-divider></span>
<span>Tübingen, Germany</span></div></div></div><div class=card-text>Research on deep learning based material acquisition.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://research.google target=_blank rel=noopener><img src=/media/icons/brands/Google.svg width=56px height=56px alt=Google loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Student Researcher</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://research.google target=_blank rel=noopener>Google</a></div><div class="text-muted exp-meta">Jun 2021 –
Apr 2022
<span class=middot-divider></span>
<span>Germany (Remote)</span></div></div></div><div class=card-text>Research on novel techniques for material, geometry and illumination disentanglement.</div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=http://www.nvidia.com target=_blank rel=noopener><img src=/media/icons/brands/Nvidia.svg width=56px height=56px alt=NVIDIA loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Research Intern</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=http://www.nvidia.com target=_blank rel=noopener>NVIDIA</a></div><div class="text-muted exp-meta">Apr 2019 –
Jul 2019
<span class=middot-divider></span>
<span>Westford, MA</span></div></div></div><div class=card-text>Research on casual shape and material acquisition, which resulted in the publication: <a href=publication/cvpr20-two-shot-brdf/>&ldquo;Two-shot Spatially-varying BRDF and Shape Estimation&rdquo;</a></div></div></div></div></div><div class="row experience"><div class="col-auto text-center flex-column d-none d-sm-flex"><div class="row h-50"><div class="col border-right">&nbsp;</div><div class=col>&nbsp;</div></div><div class=m-2><span class="badge badge-pill border">&nbsp;</span></div><div class="row h-50"><div class=col>&nbsp;</div><div class=col>&nbsp;</div></div></div><div class="col py-2"><div class=card><div class=card-body><div class="d-flex align-content-start"><div class="mr-2 mb-2"><a href=https://zahlz.com target=_blank rel=noopener><img src=/media/icons/brands/zahlz.svg width=56px height=56px alt=zahlz loading=lazy></a></div><div><div class="section-subheading card-title exp-title text-muted my-0">Android Developer</div><div class="section-subheading card-title exp-company text-muted my-0"><a href=https://zahlz.com target=_blank rel=noopener>zahlz</a></div><div class="text-muted exp-meta">Jul 2015 –
Jun 2017
<span class=middot-divider></span>
<span>Osnabrück</span></div></div></div><div class=card-text>Development of an Android Application for a mobile payment system.</div></div></div></div></div></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by><a href=/privacy/>Privacy Policy</a>
&#183;
<a href=/terms/>Legal details</a></p><p class="powered-by copyright-license-text">© 2022 Mark Boss. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.d26cbef546776b4d6032d1ea3dafadab.js></script>
<script src=https://cdn.jsdelivr.net/gh/desandro/imagesloaded@v4.1.4/imagesloaded.pkgd.min.js integrity="sha512-S5PZ9GxJZO16tT9r3WJp/Safn31eu8uWrzglMahDT4dsmgqWonRY9grk3j+3tfuPr9WJNsfooOR7Gi7HL5W2jw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/metafizzy/isotope@v3.0.6/dist/isotope.pkgd.min.js integrity="sha512-Zq2BOxyhvnRFXu0+WE6ojpZLOU2jdnqbrM1hmVdGzyeCa1DgM3X5Q4A/Is9xA1IkbUeDd7755dNNI/PzSf2Pew==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/python.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/elm.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/kotlin.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/rust.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.fe369d7ba3ba979cfdb3e0f7e5240185.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.b0d291ed6d27eacec233e6cf5204f99a.js type=module></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script></body></html>