<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>Interview Presentation</title>


<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <link rel="stylesheet" href="../reveal-js/css/reset.css">
<link rel="stylesheet" href="../reveal-js/css/reveal.css">
  <link rel="stylesheet" href="../personal.css" id="theme"><link rel="stylesheet" href="../highlight-js/atom-one-dark.min.css">
    
  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    
<section data-noprocess data-shortcode-slide
      class="title">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo logo--full"></div>
    </div>
    <div class="content">
        
        <h1>
            Neural Reflectance Decomposition
        </h1>
        
        <p class="description">
            
    Extracting BRDF, shape, and illumination from images

        </p>
    </div>
    <div class="credit">
        <hr/>
        <div class="label">Presented By</div>
        <div class="name">Mark Boss</div>
        <div class="role">PhD. Student</div>
    </div>
</div>



<aside class="notes"><ul>
<li>You found the <strong>speaker notes</strong>!</li>
</ul>
</aside>
</section>

  

    <section><div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Goal</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="height: 100%; width: 100%; display: flex; flex-direction: column; align-items: flex-start;
    justify-content: center;">
<figure><img src="../images/GnomeInput.jpg"/><figcaption>
            <h4>Multiple input images (potential multiple illuminations)</h4>
        </figcaption>
</figure>
</div>
 </div>
        
            <div class="column"> <div class="fragment" style="height: 100%; width: 100%; display: flex; flex-direction: column;
    align-items: flex-start;
    justify-content: center;">
<div style="height: 75%; width: 100%;">
<iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/nerd-results/render.html?scene=gnome"  data-preload frameborder="0">
</iframe>
</div>
<h4 style="margin-top: -0.75em;">Relightable 3D asset [1]</h4>
</div>
<div class="cite-area">
    <p>[1] <strong>Result from:</strong> Boss <em>et al.</em> - NeRD: Neural Reflectance Decomposition from Image Collections - 2021</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Applications</div>
    </div>
    <div class="content">
        <div  class="grid-flex-column" style="
        display: grid; 
        place-content: space-evenly;
        grid-template-columns: repeat(
            auto-fit, 
            minmax(
                min(
                    300px,
                    40vmin),
                1fr
            )
        );">
            
                <div class="column"> <figure><img src="../images/applications/UnityGnome_square.jpg"/><figcaption>
            <h4>Games</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/applications/BlenderGnome_square_small.jpg"/><figcaption>
            <h4>Movies</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/applications/ARGnome_small.jpg"/><figcaption>
            <h4>AR/VR</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/applications/ShopGnome.jpg"/><figcaption>
            <h4>Virtual shopping</h4>
        </figcaption>
</figure>
 </div>
            
        </div>
    </div>
</div>
</section>
    <section><div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Rendering</div>
    </div>
    <div class="content">
        
            <div class="column"> <div class="cite-area">
    <p>[1] James T. Kajiya - The Rendering Equation - 1986</p>
</div>
<h4 id="rendering-equation-1">Rendering equation [1]</h4>
<!-- $$L_{o}({\mathbf x},\omega_{o})=
    L_{e}({\mathbf x},\omega_{o}) +
    \color{red}\int_{\Omega } \color{black}
    f_{r}({\mathbf x},\omega_{i},\omega_{o}) \\
    L_{i}({\mathbf x},\omega_{i})
    (\omega_{i}\cdot{\mathbf n})
    \color{red}\operatorname d\omega_{i}$$ -->
<p class="fragment" data-fragment-index="1">$$
\definecolor{out}{RGB}{219,135,217}
\definecolor{emit}{RGB}{125,194,103}
\definecolor{int}{RGB}{127,151,236}
\definecolor{in}{RGB}{225,145,83}
\definecolor{brdf}{RGB}{0,202,207}
\definecolor{ndl}{RGB}{235,120,152}
\definecolor{point}{RGB}{232,0,19}
\color{out}L_{o}(\color{point}{\mathbf x}\color{out},\,\omega_{o})\color{black}\,=
\fragment{1}{\,\color{emit}L_{e}({\mathbf x},\,\omega_{o})}
\fragment{2}{\color{black} + \\ \color{int}\int_{\Omega }}
\fragment{4}{\color{brdf}f_{r}({\mathbf x},\,\omega_{i},\,\omega_{o})} 
\fragment{3}{\color{in}L_{i}({\mathbf x},\,\omega_{i})}\,
\fragment{5}{\color{ndl}(\omega_{i}\,\cdot\,{\mathbf n})}\,
\fragment{2}{\color{int}\operatorname d\omega_{i}}$$
</p>
<h4 class="fragment" data-fragment-index="7">Simplification: No self-emittance</h4>
<p class="fragment" data-fragment-index="7">$$
\definecolor{out}{RGB}{219,135,217}
\definecolor{emit}{RGB}{125,194,103}
\definecolor{int}{RGB}{127,151,236}
\definecolor{in}{RGB}{225,145,83}
\definecolor{brdf}{RGB}{0,202,207}
\definecolor{ndl}{RGB}{235,120,152}
\definecolor{point}{RGB}{232,0,19}
\color{out}L_{o}(\color{point}{\mathbf x}\color{out},\,\omega_{o})\color{black}\,=\,\color{int}\int_{\Omega}
\color{brdf}f_{r}({\mathbf x},\,\omega_{i},\,\omega_{o})
\color{in}L_{i}({\mathbf x},\,\omega_{i})\,
\color{ndl}(\omega_{i}\,\cdot\,{\mathbf n})\,
\color{int}\operatorname d\omega_{i}$$
</p>
<h4 class="fragment" data-fragment-index="8">Radiance, reflectance and irradiance</h4>
<!-- class="fragment" data-fragment-index="5" -->
<p class="fragment" data-fragment-index="8">$$\underbrace{L_{o}({\mathbf x},\,\omega_{o})}_{\text{Radiance (Outgoing)}}\,=\,\int_{\Omega}\underbrace{f_{r}({\mathbf x},\,\omega_{i},\,\omega_{o})}_{\text{Reflectance}} \\
\underbrace{L_{i}({\mathbf x},\,\omega_{i})\,
(\omega_{i}\,\cdot\,{\mathbf n})\,
\operatorname d\omega_{i}}_{\text{Irradiance}}$$</p>
 </div>
        
            <div class="column"> <p><svg width="100%" height="100%" viewBox="0 0 135 100" version="1.1"
xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
xml:space="preserve" xmlns:serif="http://www.serif.com/"
style="fill-rule:evenodd;clip-rule:evenodd;stroke-linecap:square;stroke-miterlimit:15;">
<g id="RenderingEquation">
<g class="fragment" data-fragment-index="3" id="Integral">
<path
d="M116.184,69.201c0,0 -2.259,12.188 -49.043,12.188c-46.785,0 -49.044,-12.048 -49.044,-12.048c0,-27.068 21.975,-49.044 49.044,-49.044c27.068,0 49.043,21.836 49.043,48.904Z"
style="fill:none;stroke:#5eb2ff;stroke-width:2.4px;" />
<ellipse cx="67.141" cy="69.201" rx="49.044" ry="12.188"
style="fill:none;stroke:#5eb2ff;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;stroke-dasharray:2.2,6.6,0,0;" />
</g>
<g class="fragment" data-fragment-index="4" id="Li">
<path
d="M57.117,64.276l5.494,4.925l-7.237,1.44c2.027,-1.155 2.899,-4.338 1.743,-6.365Z"
style="fill:#ff9d46;" />
<path d="M25.115,58.936c0,0 22.153,6.065 32.404,8.871"
style="fill:none;stroke:#ff9d46;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<path
d="M63.245,58.303l1.163,7.286l-6.527,-3.44c2.302,0.379 4.984,-1.544 5.364,-3.846Z"
style="fill:#ff9d46;" />
<path d="M41.795,34.05c0,0 13.352,18.623 19.537,27.248"
style="fill:none;stroke:#ff9d46;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<path
d="M78.683,71.496l-7.013,-2.295l6.043,-4.234c-1.389,1.875 -0.904,5.139 0.97,6.529Z"
style="fill:#ff9d46;" />
<path d="M110.386,63.451c0,0 -22.925,3.405 -33.493,4.974"
style="fill:none;stroke:#ff9d46;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
</g>
<path class="fragment" data-fragment-index="5" id="Brdf"
d="M82.214,34.634c11.767,-16.324 24.197,-27.503 27.739,-24.95c3.543,2.554 -3.135,17.88 -14.902,34.204c-11.768,16.324 -24.198,27.503 -27.74,24.95c-3.543,-2.554 3.135,-17.88 14.903,-34.204Z"
style="fill:none;stroke:#00ffe6;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<path class="fragment" data-fragment-index="6" id="dot"
d="M63.981,32.396l3.33,-6.585l3.27,6.615c-1.643,-1.657 -4.942,-1.672 -6.6,-0.03Z"
style="fill:#ff79ba;" />
<path class="fragment" data-fragment-index="6"
d="M67.141,63.551c0,0 0.099,-22.076 0.146,-32.46"
style="fill:none;stroke:#ff79ba;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<g class="fragment" data-fragment-index="2" id="Le">
<path
d="M33.977,53.139l-3.928,-6.247l7.354,0.606c-2.267,0.554 -3.98,3.374 -3.426,5.641Z"
style="fill:#89d73d;" />
<path d="M62.25,66.451c0,0 -18.825,-11.434 -27.688,-16.818"
style="fill:none;stroke:#89d73d;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<path
d="M84.862,36.75l6.475,-3.537l-1.055,7.303c-0.414,-2.297 -3.124,-4.179 -5.42,-3.766Z"
style="fill:#89d73d;" />
<path d="M69.774,64.254c0,0 12.62,-18.167 18.551,-26.705"
style="fill:none;stroke:#89d73d;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<path
d="M98.01,49.166l7.376,-0.224l-4.246,6.035c0.67,-2.235 -0.895,-5.14 -3.13,-5.811Z"
style="fill:#89d73d;" />
<path d="M72.24,66.793c0,0 19.373,-10.433 28.497,-15.347"
style="fill:none;stroke:#89d73d;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
</g>
<path class="fragment" data-fragment-index="1" id="Out"
d="M103.753,12.604l6.633,-3.234l-1.392,7.247c-0.307,-2.313 -2.927,-4.32 -5.241,-4.013Z"
style="fill:#fc90ff;" />
<path class="fragment" data-fragment-index="1"
d="M95.903,28.285c0,0 7.006,-9.151 11.273,-14.722"
style="fill:none;stroke:#fc90ff;stroke-width:2.2px;stroke-linejoin:round;stroke-miterlimit:1.5;" />
<circle class="fragment" data-fragment-index="1" cx="67.141" cy="69.201" r="2.356"
style="fill:#e80013;" />
</g>
</svg></p>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Infinitely Far Illumination</div>
    </div>
    <div class="content">
        
            <div class="column"> <div>
<p>$$
\definecolor{point}{RGB}{232,0,19}
L_{o}({\mathbf x},\,\omega_{o})\,=\,\int_{\Omega}f_{r}({\mathbf x},\,\omega_{i},\,\omega_{o})
L_{i}(\color{point}{\mathbf x}\color{black},\,\omega_{i})\,
(\omega_{i}\,\cdot\,{\mathbf n})\,
\operatorname d\omega_{i}$$</p>
<div class="fragment">
<h4>Simplification: Illumination only dependent on direction</h4>
<p>$$L_{o}({\mathbf x},\,\omega_{o})\,=\,\int_{\Omega}f_{r}({\mathbf x},\,\omega_{i},\,\omega_{o})
L_{i}(\omega_{i})\,
(\omega_{i}\,\cdot\,{\mathbf n})\,
\operatorname d\omega_{i}$$</p>
</div>
</div>
 </div>
        
            <div class="column"> <iframe type="text/html" width="100%" height="100%" data-src="../viz/infinite_distant_explainer/index.html"  data-preload frameborder="0">
</iframe>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Bidirectional Reflectance Distribution Function</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="../viz/brdf_viz/index.html"  data-preload frameborder="0">
</iframe>

    </div>
</div>
</section>
    <section><div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Challenges - Workshop Metaphor [1]</div>
    </div>
    <div class="content">
        <div  class="grid-flex-column" style="
        display: grid; 
        place-content: space-evenly;
        grid-template-columns: repeat(
            auto-fit, 
            minmax(
                min(
                    150px,
                    30%),
                1fr
            )
        );">
            
                <div class="column"> <figure><img src="../images/workshop_metaphor/Image.jpg"/><figcaption>
            <h4>Image</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/workshop_metaphor/Sculptor.jpg"/><figcaption>
            <h4>Sculptor</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/workshop_metaphor/Painter.jpg"/><figcaption>
            <h4>Painter</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/workshop_metaphor/Gaffer.jpg"/><figcaption>
            <h4>Gaffer</h4>
        </figcaption>
</figure>
 </div>
            
                <div class="column"> <figure class="fragment"><img src="../images/workshop_metaphor/Explanation.jpg"/><figcaption>
            <h4>Possible explanation</h4>
        </figcaption>
</figure>
<div class="cite-area">
    <p>[1] E.H. Adelson, A.P. Pentland - The Perception of Shading and Reflectance - 1996</p>
</div>
 </div>
            
        </div>
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Inverse Rendering</div>
    </div>
    <div class="content">
        
            <div class="column"> <h2 id="plenoptic-function">Plenoptic function</h2>
<ul>
<li>Main use-case: novel view synthesis</li>
<li>Learns the radiance</li>
<li>No relighting possible</li>
</ul>
 </div>
        
            <div class="column"> <h2 id="intrinsic-image">Intrinsic image</h2>
<ul>
<li>Splits an image into layers:
<ul>
<li>Shading (Irradiance)</li>
<li>Diffuse albedo</li>
<li>Potential: Specular shading + albedo</li>
</ul>
</li>
<li>Partial decomposition of the rendering equation</li>
<li>Albedos are accurate up to a shift and scale</li>
</ul>
 </div>
        
            <div class="column"> <h2 id="full-decomposition">Full decomposition</h2>
<ul>
<li>Decomposes the rendering equation</li>
<li>Reflectance modelled as BRDF
<ul>
<li>Often analytical</li>
</ul>
</li>
<li>Illumination as incoming radiance</li>
<li>Often differentiable rendering is used for optimization</li>
</ul>
 </div>
        
    </div>
</div>
</section>
    <section><div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Why Reflectance / Irradiance Decomposition?</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Assume dataset of 4 images</li>
<li>Images are varying illumination</li>
</ul>
<p><br/><br/></p>
<h4 class="fragment">Potential solution</h4>
<ul>
<li class='fragment'>Train GLO (<em>Generative Latent Optimization</em>) to express radiance per illumination</li>
<li class='fragment'>Interpolate between illuminations</li>
</ul>
 </div>
        
            <div class="column"> <div 
    class="grid-column" style="
        display: grid; 
        width: 100%; height: 100%;
        overflow: hidden;
        place-content: space-evenly; 
        grid-template-columns: repeat(
            auto-fit, 
            minmax(
                min(
                    40vmin,
                    45%),
                1fr
            )
        );;"
>
    <figure><img src="../viz/blend/alley.png"/>
</figure>
<figure><img src="../viz/blend/christmasphotostudio.png"/>
</figure>
<figure><img src="../viz/blend/fireonsky.png"/>
</figure>
<figure><img src="../viz/blend/studiosmall.png"/>
</figure>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> GLO Interpolation</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="../viz/blend/index.html"  data-preload frameborder="0">
</iframe>

    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Issues with GLO Interpolation</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Only interpolate between seen illuminations</li>
<li>No issue if dataset is vast and contains most illuminations</li>
<li>However, it is hard to get all possible illumination edge cases
<br />
<br /></li>
</ul>
<div style="width: 30vmin; height: 30vmin;">
<figure><img src="../viz/blend/moonlessgolf.png"/><figcaption>
            <h4>Illumination at night</h4>
        </figcaption>
</figure>
</div>
 </div>
        
            <div class="column"> <div 
    class="grid-column" style="
        display: grid; 
        width: 100%; height: 100%;
        overflow: hidden;
        place-content: space-evenly; 
        grid-template-columns: repeat(
            auto-fit, 
            minmax(
                min(
                    40vmin,
                    45%),
                1fr
            )
        );;"
>
    <figure><img src="../viz/blend/alley.png"/>
</figure>
<figure><img src="../viz/blend/christmasphotostudio.png"/>
</figure>
<figure><img src="../viz/blend/fireonsky.png"/>
</figure>
<figure><img src="../viz/blend/studiosmall.png"/>
</figure>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Full Decomposition - NeRD[1]</div>
    </div>
    <div class="content">
        <div class="cite-area">
    <p>[1] Boss <em>et al.</em> - NeRD: Neural Reflectance Decomposition from Image Collections - 2021</p>
</div>
<iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/nerd-results/render.html?scene=gnome"  data-preload frameborder="0">
</iframe>

    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Methods</h1>
    <div class="description">
        


    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Approaches</div>
    </div>
    <div class="content">
        
            <div class="column"> <div>
<h2 id="generalized-decomposition">Generalized decomposition</h2>
<ul>
<li>Models are trained on large synthetic, supervised datasets</li>
<li>For novel scenes the pre-trained weights are only evaluated</li>
<li>The results are typically of lower quality</li>
</ul>
</div>
 </div>
        
            <div class="column"> <div class="fragment">
<h2 id="per-scene-decomposition">Per-scene decomposition</h2>
<ul>
<li>Network is trained on the scene without ground truth supervision</li>
<li>The network is optimized per-scene</li>
<li>Training and fine tuning to the scene allows for higher quality</li>
</ul>
</div>
 </div>
        
    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Generalized Decomposition</h1>
    <div class="description">
        
Methods which do not require training per Scene


    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Related Work</div>
    </div>
    <div class="content">
        
            <div class="column"> <h2 id="planar-surfaces">Planar surfaces</h2>
<ul>
<li>Often co-located camera flash</li>
<li>Estimate BRDF and Surface Normal</li>
</ul>
<figure><img src="../images/generalized_decomposition/deschaintre_single_img.jpg"/><figcaption>
            <h4>Single image [1]</h4>
        </figcaption>
</figure>
<figure><img src="../images/generalized_decomposition/deschaintre_multi_img.jpg"/><figcaption>
            <h4>Multiple images with different flash locations [2]</h4>
        </figcaption>
</figure>
 </div>
        
            <div class="column"> <h2 id="objects">Objects</h2>
<ul>
<li>Shape is often encoded in depth and normal</li>
<li>Higher ambiguity due to more complex shading effects</li>
</ul>
<figure><img src="../images/generalized_decomposition/li_singleimg_object.jpg"/><figcaption>
            <h4>Single image decomposition - Input, re-rendering, and re-lighting [3]</h4>
        </figcaption>
</figure>
<div class="cite-area">
    <p>[1] Deschaintre <em>et al.</em> - Single-Image SVBRDF Capture with a Rendering-Aware Deep Network - 2018</p>
<p>[2] Deschaintre <em>et al.</em> - Flexible SVBRDF Capture with a Multi-Image Deep Network - 2019</p>
<p>[3] Li <em>et al.</em> - Learning to Reconstruct Shape and Spatially-varying Reflectance from a Single Image - 2018</p>
</div>
 </div>
        
    </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Two-shot Spatially-varying BRDF and Shape Estimation</h1>
    <div class="description">
        

Mark Boss, Varun Jampani, Kihwan Kim, Hendrik P. A. Lensch, Jan Kautz
<br/>
<em>IEEE Conference on Computer Vision and Pattern Recognition</em> 2021


    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Pipeline</div>
    </div>
    <div class="content">
        <div class="r-stack">
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step1.jpg"/><figcaption>
            <h4>Overall architecture</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step2.jpg"/><figcaption>
            <h4>Step 1: Geometry estimation</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step3.jpg"/><figcaption>
            <h4>Step 2: Illumination estimation</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step4.jpg"/><figcaption>
            <h4>Step 3: BRDF estimation</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step5.jpg"/><figcaption>
            <h4>Step 4: Re-rendering</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step6.jpg"/><figcaption>
            <h4>Step 5: Loss image for guidance</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/generalized_decomposition/twoshot/Step7.jpg"/><figcaption>
            <h4>Step 6: Joint refinement</h4>
        </figcaption>
</figure>
</div>

    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Domain Randomized Dataset</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Create large syntheic dataset (100k scenes)</li>
<li>Ground truth BRDF for supervision</li>
<li>Environment illumination and flash rendered separately
<br/><br/></li>
</ul>
<figure><img src="../images/generalized_decomposition/twoshot/Dataset.jpg"/><figcaption>
            <h4>Domain randomized dataset</h4>
        </figcaption>
</figure>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Mobile Capture App</div>
    </div>
    <div class="content">
        <video data-autoplay controls src="../images/generalized_decomposition/twoshot/MobileTwoShot.mp4" style="width: 100%;
height: 100%;
object-fit: contain;"></video>
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf7"  data-preload frameborder="0">
</iframe>

    </div>
</div>
<!-- ---

<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf2"  data-preload frameborder="0">
</iframe>

    </div>
</div>

---

<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf0"  data-preload frameborder="0">
</iframe>

    </div>
</div> -->
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=rw2"  data-preload frameborder="0">
</iframe>

    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Result</div>
    </div>
    <div class="content">
        <table>
    <caption style="caption-side:bottom"><h4>All losses are MSE except for scale invariant losses in [ ]</h4></caption>
    <thead><tr>
        <th>Method</th>
        <th>Diffuse</th>
        <th>Specular</th>
        <th>Roughness</th>
        <th>Normal</th>
        <th>Depth</th>
    </tr></thead>
    <tbody><tr>
        <td>Lasinger <i>et al.</i> [1]</td>
        <td>NA</td>
        <td>NA</td>
        <td>NA</td>
        <td>NA</td>
        <td>[0.006]</td>
    </tr>
    <tr>
        <td>Li <i>et al.</i> [2]</td>
        <td>0.160</td>
        <td>NA</td>
        <td>0.072</td>
        <td>0.034</td>
        <td>[0.024]</td>
    </tr>
    <tr>
        <td>Ours</td>
        <td><span style="color:Tomato;">0.060</span></td>
        <td><span style="color:Tomato;">0.047</span></td>
        <td><span style="color:Tomato;">0.061</span></td>
        <td><span style="color:Tomato;">0.021</span></td>
        <td><span style="color:Tomato;">[0.004]</span></td>
    </tr></tbody>
</table>
<div class="cite-area">
    <p>[1] Lasinger <em>et al.</em> - Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer - 2019</p>
<p>[2] Li <em>et al.</em> - Learning to Reconstruct Shape and Spatially-varying Reflectance from a Single Image - 2018</p>
</div>

    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Per-Scene Decomposition</h1>
    <div class="description">
        
Methods which are optimized per scene


    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Related Work - Plenoptic Function</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Learn radiance (view-dependent RGB color)</li>
<li>Goal is often novel view synthesis</li>
<li>Often neural volume rendering is used [1, 2, 3]</li>
<li>Can be extended with GLO embeddings to multiple illuminations [3]
<br/><br/></li>
</ul>
<div style="display: flex;
  justify-content: center;
  align-items: center;">
<div style="width: 60%;" >
<video data-autoplay loop src="../images/per_scene_decomposition/viewdirs_website_bww.mp4" style="width: 100%;
  object-fit: contain;"></video>
  <h4>Novel view synthesis with NeRF [1]</h4>
</div>
</div>
<div class="cite-area">
    <p>[1] Lombardi <em>et al.</em> - Neural Volumes: Learning Dynamic Renderable Volumes from Images - 2019</p>
<p>[2] Mildenhall <em>et al.</em> - NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis - 2020</p>
<p>[3] Martin-Brualla <em>et al.</em> - NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections - 2021</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Related Work - Full Decomposition</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Decompose the rendering equation into geometry, illumination &amp; reflectance</li>
<li>Neural volume rendering (NeRF-style) used [1, 2, 3, 4, 5, 6, 7]</li>
<li>Can be also used to decompose a trained NeRF model [5]</li>
<li>Specialized methods exist which directly optimize assets [6]
<br/><br/></li>
</ul>
<div style="display: flex;
  justify-content: center;
  align-items: center;">
<div style="width: 70%;" >
<figure><img src="../images/per_scene_decomposition/nerfactor.jpg"/><figcaption>
            <h4>NeRFactor [5]</h4>
        </figcaption>
</figure>
</div>
</div>
<div class="cite-area">
    <small>
<p>[1] Boss <em>et al.</em> - NeRD: Neural Reflectance Decomposition from Image Collections - 2021</p>
<p>[2] Boss <em>et al.</em> - Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition - 2021</p>
<p>[3] Zhang <em>et al.</em> - PhySG: Inverse Rendering with Spherical Gaussians for Physics-based Material Editing and Relighting - 2021</p>
<p>[4] Srinivasan <em>et al.</em> - NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis - 2021</p>
<p>[5] Zhang <em>et al.</em> - NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination - 2021</p>
<p>[6] Munkberg <em>et al.</em> - Extracting Triangular 3D Models, Materials, and Lighting From Images - 2022</p>
<p>[7] Kuang <em>et al.</em> - NeROIC: Neural Object Capture and Rendering from Online Image Collections - 2022</p>
</small>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Neural Fields</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Temporarily also known as: Coordinate-based MLPs</li>
<li>Early works encode points $p \in \mathbb{R}^3$ in network as
<ul>
<li>Occupancy [1, 2]: $f(p) \rightarrow o; o \in {0, 1}$</li>
<li>Signed Distance Field [3]: $f(p) \rightarrow d; d \in \mathbb{R}$</li>
</ul>
</li>
<li>Only encode existing point clouds or models in the neural field</li>
</ul>
 </div>
        
            <div class="column"> <figure><img src="../images/per_scene_decomposition/Deepsdf.jpg"/><figcaption>
            <h4>DeepSDF [1]</h4>
        </figcaption>
</figure>
<div class="cite-area">
    <p>[1] Chen <em>et al.</em> - Learning Implicit Fields for Generative Shape Modeling - 2019</p>
<p>[2] Mescheder <em>et al.</em> - Occupancy Networks: Learning 3D Reconstruction in Function Space - 2019</p>
<p>[3] Park <em>et al.</em> - DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation - 2019</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Neural Rendering</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Neural volumetric rendering first introduced by Lombardi <em>et al.</em> [1]
<ul>
<li>Accumulate opacity along a ray based on volume rendering
<br/><br/></li>
</ul>
</li>
</ul>
<div style="display: flex;
  justify-content: center;
  align-items: center;">
<div style="width: 70%;" >
<figure><img src="../images/per_scene_decomposition/neuralvolumerender.jpg"/><figcaption>
            <h4>Neural volumes [1]</h4>
        </figcaption>
</figure>
</div>
</div>
<br/><br/>
<div class="fragment" data-fragment-index="1">
<ul>
<li>NeRF combined neural fields with volume rendering [2]</li>
<li>Achieved photorealistic results in novel view synthesis</li>
</ul>
</div>
 </div>
        
            <div class="column"> <div class="fragment" data-fragment-index="1">
<video data-autoplay loop src="../images/per_scene_decomposition/orchid.mp4" style="width: 100%;
  object-fit: contain;"></video>
  <h4>Result from NeRF[2]</h4>
</div>
<div class="cite-area">
    <p>[1] Lombardi <em>et al.</em> - Neural Volumes: Learning Dynamic Renderable Volumes from Images - 2019</p>
<p>[2] Mildenhall <em>et al.</em> - NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis - 2020</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> NeRF[1] Visualization</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="../viz/nerf_explainer/index.html"  data-preload frameborder="0">
</iframe>
<div class="cite-area">
    <p>[1] Mildenhall <em>et al.</em> - NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis - 2020</p>
</div>

    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> NeRD: Neural Reflectance Decomposition from Image Collections</h1>
    <div class="description">
        

Mark Boss, Raphael Braun, Varun Jampani, Jonathan T. Barron, Ce Liu, Hendrik P. A. Lensch
<br/>
<em>IEEE International Conference on Computer Vision</em> 2021

    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Amplifying NeRF for Relighting</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<div class="r-stack">
<figure class="fragment fade-in-then-out"><img src="../images/per_scene_decomposition/nerd/NeRF@3x.png"/><figcaption>
            <h4>NeRF architecture</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in"><img src="../images/per_scene_decomposition/nerd/NeRFA@3x.png"/><figcaption>
            <h4>NeRF-A architecture</h4>
        </figcaption>
</figure>
</div>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<figure class="fragment"><img src="../images/per_scene_decomposition/nerd/NeRD@3x.png"/><figcaption>
            <h4>NeRD architecture</h4>
        </figcaption>
</figure>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Spherical Gaussians</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Spherical Gaussian (<em>SG</em>) have convenient properties</li>
<li>Close-form solution exists for integration 2 SGs</li>
<li>Product of 2 SGs is a SG</li>
</ul>
<div class="fragment" data-fragment-index="2">
<br/><br/>
<ul>
<li>Represent illumination as SG</li>
<li>Simpler differentiation
<ul>
<li>No sampling noise compared to Monte Carlo integration</li>
</ul>
</li>
</ul>
</div>
 </div>
        
            <div class="column"> <div 
    class="grid-column" style="
        display: grid; 
        width: 100%; height: 100%;
        overflow: hidden;
        place-content: space-evenly; 
        grid-template-columns: repeat(
            auto-fit, 
            minmax(
                min(
                    300px,
                    40vmin),
                1fr
            )
        );;"
>
    <figure><img src="../images/per_scene_decomposition/nerd/polar1d_gaussian.jpg"/><figcaption>
            <h4>Polar plot of 1D Gaussian</h4>
        </figcaption>
</figure>
<div style="display: flex;
  justify-content: flex-end;
  flex-direction: column;" class="fragment" data-fragment-index="1">
<figure><img src="../images/per_scene_decomposition/nerd/specular_lobe.jpg"/><figcaption>
            <h4>Specular lobe of BRDF</h4>
        </figcaption>
</figure>
</div>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Optimization Targets</div>
    </div>
    <div class="content">
        
            <div class="column"> <figure><img src="../images/per_scene_decomposition/nerd/NeRDTargets.png"/>
</figure>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Mesh Extraction</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Extracting textured meshes allows multiple use cases</li>
</ul>
<figure><img src="../images/per_scene_decomposition/nerd/mesh_extraction.png"/>
</figure>
 </div>
        
    </div>
</div>
</section><section>
<!-- <div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results</div>
    </div>
    <div class="content">
        
            <div class="column"> <iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/nerd-results/render.html?scene=car"  data-preload frameborder="0">
</iframe>
 </div>
        
    </div>
</div>

--- -->
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results</div>
    </div>
    <div class="content">
        
            <div class="column"> <iframe type="text/html" width="100%" height="100%" data-src="https://markboss.me/files/nerd-results/render.html?scene=chair"  data-preload frameborder="0">
</iframe>
 </div>
        
    </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      class="video-stepper">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Comparisons - Single Illumination</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<figure><img src="../images/per_scene_decomposition/nerd/cape_input.jpg"/><figcaption>
            <h4>Input</h4>
        </figcaption>
</figure>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<div class="r-stack">
<video loop src="../images/per_scene_decomposition/nerd/NeRDNeRFCape_Trim.mp4" style="width: 100%;
  object-fit: contain;" class="fragment fade-in-then-out"></video>
<video loop controls src="../images/per_scene_decomposition/nerd/NeRDNeRFCape.mp4" style="width: 100%;
  object-fit: contain;" class="fragment fade-in"></video>
</div>
</div>
 </div>
        
    </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      class="video-stepper">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Comparisons - Multiple Illumination</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<figure><img src="../images/per_scene_decomposition/nerd/gnome_input.png"/><figcaption>
            <h4>Input</h4>
        </figcaption>
</figure>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<div class="r-stack">
<video loop src="../images/per_scene_decomposition/nerd/NeRDNeRFGnome_Trim.mp4" style="width: 100%;
  object-fit: contain;" class="fragment fade-in-then-out"></video>
<video loop controls src="../images/per_scene_decomposition/nerd/NeRDNeRFGnome.mp4" style="width: 100%;
  object-fit: contain;" class="fragment fade-in"></video>
</div>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Results - Novel View Synthesis</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<table>
    <caption style="caption-side:bottom"><h4>Synthetic scenes - PSNR</h4></caption>
    <thead><tr>
        <th>Method</th>
        <th>Single</th>
        <th>Multiple</th>
    </tr></thead>
    <tbody><tr>
        <td>NeRF</td>
        <td><span style="color:Tomato;">34.24</span></td>
        <td>21.05</td>
    </tr>
    <tr>
        <td>NeRF-A</td>
        <td>32.44</td>
        <td><span style="color:Tomato;">28.53</span></td>
    </tr>
    <tr>
        <td>NeRD (Ours)</td>
        <td>30.07</td>
        <td>27.96</td>
    </tr></tbody>
</table>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;" class="fragment">
<table>
    <caption style="caption-side:bottom"><h4>Real world scenes - PSNR</h4></caption>
    <thead><tr>
        <th>Method</th>
        <th>Single</th>
        <th>Multiple</th>
    </tr></thead>
        <tbody><tr>
        <td>NeRF</td>
        <td>23.34</td>
        <td>20.11</td>
    </tr>
    <tr>
        <td>NeRF-A</td>
        <td>22.87</td>
        <td><span style="color:Tomato;">26.36</span></td>
    </tr>
    <tr>
        <td>NeRD (Ours)</td>
        <td><span style="color:Tomato;">23.86</span></td>
        <td>25.81</td>
    </tr></tbody>
</table>
</div>
 </div>
        
    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</h1>
    <div class="description">
        

Mark Boss, Varun Jampani, Raphael Braun, Ce Liu, Jonathan T. Barron, Hendrik P. A. Lensch
<br/>
<em>Advances in Neural Information Processing Systems</em> 2021


    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Issues with Spherical Gaussians</div>
    </div>
    <div class="content">
        
            <div class="column"> <video data-autoplay style="width: 100%;
height: 100%;
object-fit: contain;">
<source data-src="../images/per_scene_decomposition/neural_pil/sgs_issues.mp4" type="video/mp4" />
</video> </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Pre-Integrated Illumination [1]</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Pre-compute light integrals for fast rendering</li>
</ul>
<div class="r-stack">
<p class="fragment fade-in-then-out" data-fragment-index="0">$L_o(x,\omega_o) = \underbrace{\frac{c_d}{\pi} \int_\Omega L_i(x, \omega_i) (\omega_i \cdot n) d\omega_i}_{\text{Diffuse}} + \underbrace{\int_\Omega f_r(x,\omega_i,\omega_o; c_s, c_r) L_i(x, \omega_i)(\omega_i \cdot n) d\omega_i}_{\text{Specular}}$</p>
<p class="fragment fade-in" data-fragment-index="1">$L_o(x,\omega_o) = \underbrace{\frac{c_d}{\pi} \color{red}\boxed{\color{black}\int_\Omega L_i(x, \omega_i)}\color{black} (\omega_i \cdot n) d\omega_i}_{\text{Diffuse}} + \underbrace{\color{red}\boxed{\color{black}\int_\Omega}\color{black} f_r(x,\omega_i,\omega_o; c_s, c_r) \color{red}\boxed{\color{black}L_i(x, \omega_i)}\color{black} (\omega_i \cdot n) d\omega_i}_{\text{Specular}}$</p>
</div>
<div class="fragment" data-fragment-index="1">
<h4>Pre-integrated light formulation</h4>
<p>$$\color{red}\boxed{\color{black}\tilde{L}_i(\omega_r, c_r)}\color{black} = \int_\Omega D(c_r, \omega_i, \omega_r)L_i(x, \omega_i)d\omega_i$$</p>
</div>
<div class="fragment" data-fragment-index="2">
<h4>Pre-integrated rendering equation</h4>
<p>$$L_o(x,\omega_o) \approx \underbrace{\frac{c_d}{\pi} \tilde{L}_i(n, 1)}_{\text{Diffuse}} + \underbrace{b_s (F_0(\omega_o,n)B_0(\omega_o \cdot n, c_r) + B_1(\omega_o \cdot n, c_r)) \tilde{L}_i(\omega_r, c_r)}_{\text{Specular}}$$</p>
</div>
<div class="cite-area">
    <p>[1] Karis <em>et al.</em> - Real Shading in Unreal Engine 4</p>
</div>
 </div>
        
    </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      class="video-stepper">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Pre-Integrated Illumination [1]</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<div class="r-stack">
<p><video src="../images/per_scene_decomposition/neural_pil/preint_pt1.mp4" style="width: 100%; height: 100%;
object-fit: contain;" class="fragment fade-in-then-out">
</video></p>
<p><video src="../images/per_scene_decomposition/neural_pil/preint_pt2.mp4" style="width: 100%; height: 100%;
object-fit: contain;" class="fragment fade-in-then-out">
</video></p>
<p><video src="../images/per_scene_decomposition/neural_pil/preint_pt3.mp4" style="width: 100%; height: 100%;
object-fit: contain;" class="fragment fade-in">
</video></p>
</div>
</div>
<div class="cite-area">
    <p>[1] Karis <em>et al.</em> - Real Shading in Unreal Engine 4</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Neural-PIL</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Light pre-integration is still expensive</li>
<li>We need to do the pre-integration on the fly</li>
<li>Neural-PIL that converts light pre-integration into a simple network query</li>
<li>Architecture based on pi-GAN [1]</li>
</ul>
<table class="fragment" data-fragment-index="4">
    <caption style="caption-side:bottom"><h4>Evaluation time</h4></caption>
    <thead><tr>
    <th>Rendering</th>
    <th>SGs</th>
    <th>Neural PIL</th>
    </tr></thead>
    <tbody><tr>
      <td>1 Million Samples</td>
      <td>0.21s</td>
      <td style="color:Tomato;">0.00186s</td>
    </tr></tbody>
</table>
 </div>
        
            <div class="column"> <div class="r-stack">
<figure class="fragment fade-in-then-out"><img src="../images/per_scene_decomposition/neural_pil/neural_pil1.jpg"/><figcaption>
            <h4>Neural-PIL architecture</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in-then-out"><img src="../images/per_scene_decomposition/neural_pil/neural_pil2.jpg"/><figcaption>
            <h4>Neural-PIL architecture</h4>
        </figcaption>
</figure>
<figure class="fragment fade-in"><img src="../images/per_scene_decomposition/neural_pil/neural_pil3.jpg"/><figcaption>
            <h4>Neural-PIL architecture</h4>
        </figcaption>
</figure>
</div>
<div class="cite-area">
    <p>[1] Chan <em>et al.</em> – pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis - 2021</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Neural-PIL Demo</div>
    </div>
    <div class="content">
        
            <div class="column"> <iframe type="text/html" width="100%" height="100%" data-src="../viz/illum_smae/index.html"  data-preload frameborder="0">
</iframe>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Comparison</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex; justify-content: center;
  align-items: center; width: 100%; height: 100%;">
<div style="width: 80%;">
<figure><img src="../images/per_scene_decomposition/neural_pil/sgs_vs_neuralpil_vs_mc.png"/><figcaption>
            <h4>SGs vs. Monte-Carlo vs. Neural-PIL</h4>
        </figcaption>
</figure>
</div>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Smooth Manifold</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Learn a smooth low-dimensional manifold to represent BRDF and lighting</li>
<li>Constraints BRDF and light to plausible values</li>
<li>Auto-encoder learning with interpolated latent space</li>
<li>Smooth manifold losses include:
<ul>
<li>Adversarial</li>
<li>Gradient regularization during manifold interpolation</li>
</ul>
</li>
</ul>
 </div>
        
            <div class="column"> <figure><img src="../images/per_scene_decomposition/neural_pil/smae_loss.jpg"/><figcaption>
            <h4>Smooth manifold training</h4>
        </figcaption>
</figure>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> BRDF SMAE Smoothness</div>
    </div>
    <div class="content">
        <iframe type="text/html" width="100%" height="100%" data-src="../viz/brdf_smae/index.html"  data-preload frameborder="0">
</iframe>

    </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      class="video-stepper">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Comparisons - Single Illumination</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<figure><img src="../images/per_scene_decomposition/nerd/cape_input.jpg"/><figcaption>
            <h4>Input</h4>
        </figcaption>
</figure>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<div class="r-stack">
<video loop src="../images/per_scene_decomposition/neural_pil/comparison_Trim.mp4" style="width: 100%;
  object-fit: contain;" class="fragment fade-in-then-out"></video>
<video loop controls src="../images/per_scene_decomposition/neural_pil/comparison.mp4" style="width: 100%;
  object-fit: contain;" class="fragment fade-in"></video>
</div>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Multiple Illumination Reconstruction</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center; 
  flex-direction: column;
  align-items: center; height: 100%;">
<p><video data-autoplay loop src="../images/per_scene_decomposition/neural_pil/car.mp4" style="width: 100%;
object-fit: contain;"></video></p>
<div style="display: flex; flex-direction: row; justify-content: center; align-items: center; width: 100%">
<figure><img src="../images/per_scene_decomposition/neural_pil/car1.jpg"/>
</figure>
<figure><img src="../images/per_scene_decomposition/neural_pil/car2.jpg"/>
</figure>
<figure><img src="../images/per_scene_decomposition/neural_pil/car3.jpg"/>
</figure>
</div>
<h4>Examplary input</h4>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center; 
  flex-direction: column;
  align-items: center; height: 100%;">
<p><video data-autoplay loop src="../images/per_scene_decomposition/neural_pil/chair.mp4" style="width: 100%;
object-fit: contain;"></video></p>
<div style="display: flex; flex-direction: row; justify-content: center; align-items: center; width: 100%">
<figure><img src="../images/per_scene_decomposition/neural_pil/chair1.jpg"/>
</figure>
<figure><img src="../images/per_scene_decomposition/neural_pil/chair2.jpg"/>
</figure>
<figure><img src="../images/per_scene_decomposition/neural_pil/chair3.jpg"/>
</figure>
</div>
<h4>Examplary input</h4>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center; 
  flex-direction: column;
  align-items: center; height: 100%;">
<p><video data-autoplay loop src="../images/per_scene_decomposition/neural_pil/globe.mp4" style="width: 100%;
object-fit: contain;"></video></p>
<div style="display: flex; flex-direction: row; justify-content: center; align-items: center; width: 100%">
<figure><img src="../images/per_scene_decomposition/neural_pil/globe1.jpg"/>
</figure>
<figure><img src="../images/per_scene_decomposition/neural_pil/globe2.jpg"/>
</figure>
<figure><img src="../images/per_scene_decomposition/neural_pil/globe3.jpg"/>
</figure>
</div>
<h4>Examplary input</h4>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Result</div>
    </div>
    <div class="content">
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;">
<table>
    <caption style="caption-side:bottom"><h4>Synthetic scenes - PSNR</h4></caption>
    <thead><tr>
        <th>Method</th>
        <th>Single</th>
        <th>Multiple</th>
    </tr></thead>
    <tbody><tr>
        <td>NeRF</td>
        <td><span style="color:Tomato;">34.24</span></td>
        <td>21.05</td>
    </tr>
    <tr>
        <td>NeRF-A</td>
        <td>32.44</td>
        <td>28.53</td>
    </tr>
    <tr>
        <td>NeRD (Ours)</td>
        <td>30.07</td>
        <td>27.96</td>
    </tr>
    <tr>
        <td>Neural-PIL (Ours)</td>
        <td>30.08</td>
        <td><span style="color:Tomato;">29.24</span></td>
    </tr></tbody>
</table>
</div>
 </div>
        
            <div class="column"> <div style="display: flex;
  justify-content: center;
  align-items: center; height: 100%;" class="fragment">
<table>
    <caption style="caption-side:bottom"><h4>Real world scenes - PSNR</h4></caption>
    <thead><tr>
        <th>Method</th>
        <th>Single</th>
        <th>Multiple</th>
    </tr></thead>
        <tbody><tr>
        <td>NeRF</td>
        <td>23.34</td>
        <td>20.11</td>
    </tr>
    <tr>
        <td>NeRF-A</td>
        <td>22.87</td>
        <td><span style="color:Tomato;">26.36</span></td>
    </tr>
    <tr>
        <td>NeRD (Ours)</td>
        <td>23.86</td>
        <td>25.81</td>
    </tr>
    <tr>
        <td>Neural-PIL (Ours)</td>
        <td><span style="color:Tomato;">23.95</span></td>
        <td>26.23</td>
    </tr></tbody>
</table>
</div>
 </div>
        
    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Conclusion</h1>
    <div class="description">
        


    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Conclusion</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Solving the inverse rendering problem is highly ill-posed</li>
</ul>
<div class="fragment">
<ul>
<li>Two approaches developed to enable the decomposition
<ul>
<li>Generalized methods which leverage statistical knowledge from datasets</li>
<li>Unsupervised optimization based methods which fit decomposition to a scene</li>
</ul>
</li>
</ul>
</div>
<div class="fragment">
<ul>
<li>Neural-PIL is combination of approaches
<ul>
<li>Prior knowledge from datasets for BRDF and illumination</li>
<li>Optimized to specific scene</li>
<li>Outperforms prior art</li>
</ul>
</li>
</ul>
</div>
 </div>
        
    </div>
</div>
</section>
    
<section data-noprocess data-shortcode-slide
      class="subsection">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
    </div>
    <h1> Outlook</h1>
    <div class="description">
        
Discussion future research

    </div>
</div>
</section><section>
<!-- <div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Outlook - Overall Goal</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li></li>
</ul>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: flex-start;
  align-items: center; width: 100%; height: 100%;">
<div style="height: 80%; width: 100%;">
<video data-autoplay loop src="../images/outlook/google_ar_search.mp4" style="width: 100%;
  object-fit: contain;"></video>
</div>
<h4>AR Image Search</h4>
</div>
 </div>
        
    </div>
</div> -->
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Outlook - Training Times</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Training takes about 2 days for NeRD/Neural-PIL</li>
<li>Recently Instant-NGP[1] or TensoRF[2] achieve fast training</li>
</ul>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: center;
  align-items: center; width: 100%; height: 100%;">
<div style="width: 90%;" class="fragment">
<figure><img src="../images/outlook/instant-ngp.jpg"/><figcaption>
            <h4>Instant-NGP&#39;s hash enconding [1]</h4>
        </figcaption>
</figure>
</div>
<div style="width: 90%;" class="fragment">
<figure><img src="../images/outlook/tensorf.jpg"/><figcaption>
            <h4>TensoRF&#39;s vector-matrix decomposition [2]</h4>
        </figcaption>
</figure>
</div>
</div>
<div class="cite-area">
    <p>[1] Müller <em>et al.</em> - Instant Neural Graphics Primitives with a Multiresolution Hash Encoding - 2022</p>
<p>[2] Chen <em>et al.</em> - TensoRF: Tensorial Radiance Fields - 2022</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Outlook - Illumination Quality</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Neural-PIL improved illumination quality</li>
<li>Still mostly low-frequent</li>
<li>For single illumination Munkberg <em>et al.</em> [1] achieved high frequent details
<ul>
<li>Environment map optimized per pixel</li>
</ul>
</li>
</ul>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: center;
  align-items: center; width: 100%; height: 100%;">
<div style="width: 90%;">
<figure><img src="../images/outlook/nvdiffrec_sgs_quality.jpg"/><figcaption>
            <h4>Comparison with SGs and Munkberg et al. [1]</h4>
        </figcaption>
</figure>
</div>
</div>
<div class="cite-area">
    <p>[1] Munkberg <em>et al.</em> - Extracting Triangular 3D Models, Materials, and Lighting From Images - 2022</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Limitations - Shadows, Inter-reflections &amp; Transparency</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Currently only a direct light is taken into account
<ul>
<li>NeRV [1] stores indirect light in a neural field</li>
<li>Combine global infinite far illumination with local indirect illumination</li>
</ul>
</li>
<li>No shadows
<ul>
<li>Representable as transient effects [2]</li>
</ul>
</li>
<li>Transparency, <em>e.g.</em> glass or water, is also not taken into account</li>
</ul>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: center;
  align-items: center; width: 100%; height: 100%;">
<div style="width: 70%;" class="fragment">
<figure><img src="../images/outlook/nerv-one-bounce.jpg"/><figcaption>
            <h4>NeRV stores the indirect light in a neural field [1]</h4>
        </figcaption>
</figure>
</div>
<div style="width: 70%;" class="fragment">
<figure><img src="../images/outlook/neroic-transient.jpg"/><figcaption>
            <h4>NeROIC blends transient RGB colors with the rendering [2]</h4>
        </figcaption>
</figure>
</div>
</div>
<div class="cite-area">
    <p>[1] Srinivasan <em>et al.</em> - NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis - 2021</p>
<p>[2] Kuang <em>et al.</em> - NeROIC: Neural Object Capture and Rendering from Online Image Collections - 2022</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Outlook - Dynamic Scenes</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Currently only static scenes</li>
<li>Even scenes without humans move due to wind (Trees)</li>
<li>NeRFies [1] or HyperNeRF [2] bend the ray based on the time step</li>
</ul>
<figure><img src="../images/outlook/nerfies.jpg"/><figcaption>
            <h4>Nerfies bend the ray for the volume sampling [1]</h4>
        </figcaption>
</figure>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: flex-start;
  align-items: center; width: 100%; height: 100%;" class="fragment">
<div style="height: 80%; width: 100%;">
<video data-autoplay loop src="../images/outlook/chair-tp.mp4" style="width: 100%;
  object-fit: contain;"></video>
</div>
<h4>Result from Nerfies[1]</h4>
</div>
<div class="cite-area">
    <p>[1] Park <em>et al.</em> - Nerfies: Deformable Neural Radiance Fields - 2021</p>
<p>[2] Park <em>et al.</em> - A Higher-Dimensional Representation
for Topologically Varying Neural Radiance Fields - 2021</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Outlook - Larger Scenes</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Decompose rooms or large buildings (churches)</li>
<li>Illumination is not global and inter-reflections play a large role</li>
</ul>
<div style="display: flex; flex-direction: column; justify-content: flex-start;
  align-items: center; width: 100%; height: 100%;">
<div style="height: 80%; width: 70%;">
<figure><img src="../images/outlook/BlockNerf.jpg"/><figcaption>
            <h4>Block NeRF composes several NeRFs [1]</h4>
        </figcaption>
</figure>
</div>
</div>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: flex-start;
  align-items: center; width: 100%; height: 100%;">
<div style="height: 80%; width: 100%;">
<video data-autoplay loop src="../images/outlook/waymo_block_nerf_grace_cathedral.mp4" style="width: 100%;
  object-fit: contain;"></video>
</div>
<h4>Result from Block-NeRF[1]</h4>
</div>
<div class="cite-area">
    <p>[1] Tancik <em>et al.</em> - Block-NeRF: Scalable Large Scene Neural View Synthesis - 2022</p>
</div>
 </div>
        
    </div>
</div>
</section><section>
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Outlook - No Optimization / Few Shot</div>
    </div>
    <div class="content">
        
            <div class="column"> <ul>
<li>Reduce number of images per decomposition</li>
<li>Skip training entirely (even with reduced quality)
<br/><br/></li>
</ul>
<div class="fragment">
<figure><img src="../images/outlook/ibrnet.jpg"/><figcaption>
            <h4>IBRnet does not require training per scene [2]</h4>
        </figcaption>
</figure>
</div>
 </div>
        
            <div class="column"> <div style="display: flex; flex-direction: column; justify-content: flex-start;
  align-items: center; width: 100%; height: 100%;">
<div style="height: 80%; width: 100%;">
<figure><img src="../images/outlook/regnerf.jpg"/><figcaption>
            <h4>Result from RegNeRF with 3 input images [1]</h4>
        </figcaption>
</figure>
</div>
</div>
<div class="cite-area">
    <p>[1] Niemeyer <em>et al</em> - RegNeRF: Regularizing Neural Radiance Fields
for View Synthesis from Sparse Inputs - 2022</p>
<p>[2] Wang <em>et al.</em> - IBRNet: Learning Multi-View Image-Based Rendering - 2021</p>
</div>
 </div>
        
    </div>
</div>
</section>
    <section><div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Publications</div>
    </div>
    <div class="content">
        <div>
<h5 style="margin-bottom: 1vmin;">Medicine quality screening: TLCyzer, an open-source smartphone-based imaging algorithm for quantitative evaluation of thin-layer chromatographic analyses using the GPHF Minilab</h5>
<small style="margin-bottom: 2.5vmin">Cathrin Hauk, <strong>Mark Boss</strong>, Julia Gabel, Simon Schäfermann,  Hendrik P. A. Lensch, Lutz Heide - <em>Under Submission</em> - 2022</small>
<h5 style="margin-bottom: 1vmin;">Neural-PIL: Neural Pre-Integrated Lighting for Reflectance Decomposition</h5>
<small style="margin-bottom: 2.5vmin"><strong>Mark Boss</strong>, Varun Jampani, Raphael Braun, Ce Liu, Jonathan T. Barron, Hendrik P. A. Lensch - <em>Advances in Neural Information Processing Systems</em> - 2021</small>
<h5 style="margin-bottom: 1vmin;">NeRD: Neural Reflectance Decomposition from Image Collections</h5>
<small style="margin-bottom: 2.5vmin"><strong>Mark Boss</strong>, Raphael Braun, Varun Jampani, Jonathan T. Barron, Ce Liu, Hendrik P. A. Lensch - <em>IEEE International Conference on Computer Vision</em> - 2021</small>
<h5 style="margin-bottom: 1vmin;">Two-shot Spatially-varying BRDF and Shape Estimation</h5>
<small style="margin-bottom: 2.5vmin"><strong>Mark Boss</strong>, Varun Jampani, Kihwan Kim, Hendrik P. A. Lensch, Jan Kautz - <em>IEEE Conference on Computer Vision and Pattern Recognition</em> - 2020</small>
<h5 style="margin-bottom: 1vmin;">Single Image BRDF Parameter Estimation with a Conditional Adversarial Network</h5>
<small style="margin-bottom: 2.5vmin"><strong>Mark Boss</strong>, Hendrik P. A. Lensch - <em>ArXiv</em> - 2019</small>
<h5 style="margin-bottom: 1vmin;">Deep Dual Loss BRDF Parameter Estimation</h5>
<small style="margin-bottom: 2.5vmin"><strong>Mark Boss</strong>, Fabian Groh, Sebastian Herholz, Hendrik P. A. Lensch - <em>Workshop on Material Appearance Modeling</em> - 2018</small>
</div>

    </div>
</div>
</section>

<section data-noprocess data-shortcode-slide
      class="end">
  
<div class="grid-wrapper">
    <div class="header">
        <div class="logo"></div>
        <div class="section"> Invisible</div>
    </div>
    <div class="content">
        <h1 id="thank-you-for-listening">Thank you for listening</h1>

    </div>
</div>



<aside class="notes"><ul>
<li>You found the <strong>speaker notes</strong>!</li>
</ul>
</aside>
</section>

</div>
      

    </div>
<script type="text/javascript" src=../reveal-hugo/object-assign.js></script>

<a href="../reveal-js/css/print/" id="print-location" style="display: none;"></a>
<script type="text/javascript">
  var printLocationElement = document.getElementById('print-location');
  var link = document.createElement('link');
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = printLocationElement.href + (window.location.search.match(/print-pdf/gi) ? 'pdf.css' : 'paper.css');
  document.getElementsByTagName('head')[0].appendChild(link);
</script>

<script type="application/json" id="reveal-hugo-site-params">null</script>
<script type="application/json" id="reveal-hugo-page-params">{"center":false,"custom_theme":"personal-theme.scss","custom_theme_compile":true,"disable_layout":true,"height":"100%","highlight_theme":"atom-one-dark","margin":0,"max_scale":1,"min_scale":1,"plugins":["plugins/math.js"],"slide_number":true,"width":"100%"}</script>

<script src="../reveal-js/js/reveal.js"></script>

<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }
  
  var revealHugoDefaults = { math: {
				mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
				config: 'TeX-AMS_HTML-full',
				TeX: {
					extensions: ["color.js"]
				},
        
        "HTML-CSS": { availableFonts: ["TeX"], linebreaks: { automatic: true } },
        SVG: { linebreaks: { automatic: true } }
			},center: true, controls: true, history: true, progress: true, transition: "slide" };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams));
  Reveal.initialize(options);

  

function playCurrentFragment() {
  [].slice.call( document.querySelectorAll('.fragment') ).forEach(function(fragment) {

    if(fragment.tagName == "VIDEO"){
      var video = fragment;
      if(video.classList.contains('current-fragment')) {
        video.play();
      }
      else {
        
      }
    }

  });
}

Reveal.addEventListener( 'fragmentshown', playCurrentFragment );
Reveal.addEventListener( 'fragmenthidden', playCurrentFragment );

</script>


  
  
  <script type="text/javascript" src="../reveal-js/plugin/markdown/marked.js"></script>
  
  <script type="text/javascript" src="../reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="../reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="../reveal-js/plugin/zoom-js/zoom.js"></script>
  
  
  <script type="text/javascript" src="../reveal-js/plugin/notes/notes.js"></script>



<script type="text/javascript" src="../plugins/math.js"></script>

    
    
  </body>
</html>
