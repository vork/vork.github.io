<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Mark Boss</title><link>https://markboss.me/</link><atom:link href="https://markboss.me/index.xml" rel="self" type="application/rss+xml"/><description>Mark Boss</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 06 Dec 2020 11:57:23 +0100</lastBuildDate><image><url>https://markboss.me/images/icon_hube1743d0a4940c76c300ec8349475861_6659_512x512_fill_lanczos_center_2.png</url><title>Mark Boss</title><link>https://markboss.me/</link></image><item><title>NeRD: Neural Reflectance Decomposition from Image Collections</title><link>https://markboss.me/news/arxiv20-nerd/</link><pubDate>Sun, 06 Dec 2020 11:57:23 +0100</pubDate><guid>https://markboss.me/news/arxiv20-nerd/</guid><description>&lt;!-- **[ArXiv](https://arxiv.org/abs/2004.00403)** --></description></item><item><title>Online BRDF Visualization</title><link>https://markboss.me/project/web_brdf_viz/</link><pubDate>Tue, 01 Dec 2020 10:32:39 +0100</pubDate><guid>https://markboss.me/project/web_brdf_viz/</guid><description>&lt;p>A bidirectional reflectance distribution function (BRDF) is a function which defines how incoming light $\omega_i$ is reflected to every outgoing direction $\omega_o$ on the hemisphere $f_r(\omega_i, \omega_o)$. A BRDF can be measured by capturing a surface from various known view and light positions. The information can then be stored in a texture where the x and y coordinates represent the corresponding view and light direction. This is mostly only done for materials that do not vary over the surface due to the information density. Therefore, often analytical BRDF models are used. Parameters are then used to build a function that can be queried for all incoming and outgoing directions. One popular model is the &lt;a href="https://dl.acm.org/doi/10.1145/357290.357293" target="_blank" rel="noopener">Cook-Torrance&lt;/a> model, which parametrizes the BRDF with a diffuse and specular color plus a roughness value. The model is split into a diffuse and specular lobe. Below is an interactive visualizer, where you can change the diffuse, specular, and roughness parameters.&lt;/p>
&lt;div style="width: 100%; padding-top: 100%; position: relative;">
&lt;iframe src="https://markboss.me/files/brdf_viz/brdf_eval.html" width="100%" height="100%" frameborder=" 0 " style="position: absolute; top: 0;
left: 0;
bottom: 0;
right: 0;">&lt;/iframe>
&lt;/div>
&lt;p>Interpolating between random BRDFs is also quite soothing:&lt;/p>
&lt;div style="width: 100%; padding-top: 100%; position: relative;">
&lt;iframe src="https://markboss.me/files/brdf_viz/brdf_eval.html?rngesus=1" width="100%" height="100%" frameborder=" 0 " style="position: absolute; top: 0;
left: 0;
bottom: 0;
right: 0;">&lt;/iframe>
&lt;/div>
&lt;p>If you want to use this interactive visualizer for teaching, feel free to use it: &lt;a href="https://markboss.me/files/brdf_viz/brdf_eval.html">link&lt;/a>.&lt;/p></description></item><item><title>NeRD: Neural Reflectance Decomposition from Image Collections</title><link>https://markboss.me/publication/2021-nerd/</link><pubDate>Fri, 27 Nov 2020 00:00:00 +0000</pubDate><guid>https://markboss.me/publication/2021-nerd/</guid><description>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/JL-qMTXw9VU" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h3 id="introduction">Introduction&lt;/h3>
&lt;p>NeRD is a novel method that can decompose image collections from multiple views taken under varying or fixed illumination conditions. The object can be rotated, or the camera can turn around the object. The result is a neural volume with an explicit representation of the appearance and illumination in the form of the BRDF and Spherical Gaussian (SG) environment illumination.&lt;/p>
&lt;p>The method is based on the general structure of &lt;a href="https://www.matthewtancik.com/nerf" target="_blank" rel="noopener">NeRF&lt;/a>. However, NeRF encodes the scene to an implicit BRDF representation where a Multi-Layer-Perceptron (MLP) is queried for outgoing view directions at every point. Extracting information from NeRF is therefore not easily done, and the inference time for novel views takes around 30 seconds. Also, NeRF is not capable of relighting an object under any illumination. By introducing physically-based representations for lighting and appearance, NeRD can relighting an object, and information can be extracted from the neural volume. After our extraction process, the result is a regular texture mesh that can be rendered in real-time. See our &lt;a href="#results">results&lt;/a> where we provide a web-based interactive renderer.&lt;/p>
&lt;h3 id="method">Method&lt;/h3>
&lt;p>Decomposing the scene requires that the integral over the hemisphere from the rendering equation is decomposed into its parts. Here, we use a simplified version without self-emittance.
$$L_o(x,\omega_o) = \int_\Omega L_i(x,\omega_i) f_r(x,\omega_i,\omega_o) (\omega_i \cdot n) d\omega_i$$
Here, $L_o$ is the outgoing radiance for a point $x$ in the direction $\omega_o$. This radiance is calculated by integrating all influences over the hemisphere $\Omega$, which are based on the incoming light $L_i$ for each direction $\omega_i$. The surface behavior is expressed as the BRDF $f_r$, which describes how incoming light $\omega_i$ is directed to the outgoing direction $\omega_o$. Lastly, a cosine term is used $(\omega_i \cdot n)$, which reduces the received light based on the angle towards the light source.&lt;/p>
&lt;p>The inverse of this integral is highly ambiguous, and we use several approximations to solve it. We do not use any interreflections or shadowing, which means that we do not compute the incoming radiance recursively. Additionally, our illumination is expressed as SG, which reduces a full continuous integral to - in our case - 24 evaluation of the environment SGs.&lt;/p>
&lt;!-- Our image formation is now expressed as:
$$L_o(x,\omega_o) \approx \sum^{24}_{m=1} \rho_d(\omega_o,\Gamma,x) + \rho_s(\omega_o,\Gamma,x)$$
Where $\Gamma$ defines the parameters for the SGs, $\rho_d$ defines the evaluation for the diffuse part of the BRDF, and $\rho_s$ for the specular component. -->
&lt;figure id="figure-steps-of-the-query-process-in-a-the-volume-is-constructed-by-tracing-rays-from-each-camera-into-the-scene-then-samples-are-placed-along-with-the-rays-in-b-and-based-on-the-density-at-each-sampling-point-additional-samples-are-placed-in-c-the-samples-are-then-evaluated-into-a-brdf-which-is-re-rendered-using-the-jointly-optimized-illumination-in-d">
&lt;a data-fancybox="" href="https://markboss.me/publication/2021-nerd/methodoverview_hu30910665284931ace4f57faa1e01d828_73318_2000x2000_fit_q80_lanczos.jpg" data-caption="Steps of the query process. In a) the volume is constructed by tracing rays from each camera into the scene. Then samples are placed along with the rays in b), and based on the density at each sampling point, additional samples are placed in c). The samples are then evaluated into a BRDF, which is re-rendered using the jointly optimized illumination in d).">
&lt;img data-src="https://markboss.me/publication/2021-nerd/methodoverview_hu30910665284931ace4f57faa1e01d828_73318_2000x2000_fit_q80_lanczos.jpg" class="lazyload" alt="" width="960" height="540">
&lt;/a>
&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
Steps of the query process. In a) the volume is constructed by tracing rays from each camera into the scene. Then samples are placed along with the rays in b), and based on the density at each sampling point, additional samples are placed in c). The samples are then evaluated into a BRDF, which is re-rendered using the jointly optimized illumination in d).
&lt;/figcaption>
&lt;/figure>
&lt;p>Inspired by NeRF the method uses two MLPs, which encode the each position in the volume $\textbf{x} = (x,y,z)$ to a volume density $\sigma$ and a color or BRDF parameters. &lt;a href="#figure-steps-of-the-query-process-in-a-the-volume-is-consturcted-by-tracing-rays-from-each-camera-into-the-scene-then-samples-are-placed-along-the-rays-in-b-and-based-on-the-density-at-each-sampling-point-additional-samples-are-placed-in-c-the-samples-are-then-evaluated-into-a-brdf-which-is-re-rendered-using-the-jointly-optimized-illumination-in-d">Figure 1&lt;/a> shows an overview of this optimization process.&lt;/p>
&lt;!-- Similar to NeRF, two networks are trained in conjunction. A training and inference step consists of first creating a rough sampling pattern using our *sampling network*, which learns the object's rough shape. Samp -->
&lt;!--
&lt;figure id="figure-overview-of-the-sampling-network">
&lt;a data-fancybox="" href="https://markboss.me/publication/2021-nerd/sampling_hu196f0511f68819ecb55f8ee2b8043621_32888_2000x2000_fit_q80_lanczos.jpg" data-caption="Overview of the sampling network.">
&lt;img data-src="https://markboss.me/publication/2021-nerd/sampling_hu196f0511f68819ecb55f8ee2b8043621_32888_2000x2000_fit_q80_lanczos.jpg" class="lazyload" alt="" width="712" height="340">
&lt;/a>
&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
Overview of the sampling network.
&lt;/figcaption>
&lt;/figure>
&lt;figure id="figure-overview-of-the-decomposition-network">
&lt;a data-fancybox="" href="https://markboss.me/publication/2021-nerd/decomposition_huf360bbca0ddfda6b4bca5b3617a09fb5_64813_2000x2000_fit_q80_lanczos.jpg" data-caption="Overview of the decomposition network.">
&lt;img data-src="https://markboss.me/publication/2021-nerd/decomposition_huf360bbca0ddfda6b4bca5b3617a09fb5_64813_2000x2000_fit_q80_lanczos.jpg" class="lazyload" alt="" width="1055" height="482">
&lt;/a>
&lt;figcaption data-pre="Figure&amp;nbsp;" data-post=":&amp;nbsp;" class="numbered">
Overview of the decomposition network.
&lt;/figcaption>
&lt;/figure>
-->
&lt;!--
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/CyC6PutoJO8" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
-->
&lt;h3 id="results">Results&lt;/h3>
&lt;div class="alert alert-note">
&lt;div>
Click the images for an interactive 3D visualization.
&lt;/div>
&lt;/div>
&lt;h4 id="real-world">Real-world&lt;/h4>
&lt;div class="gallery">
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/nerd-results/render.html?scene=gnome" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/nerd-results/assets/models/gnome/input.jpg" alt="">
&lt;/a>
&lt;/div>
&lt;h5 id="synthetic-examples">Synthetic Examples&lt;/h5>
&lt;div class="gallery">
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/nerd-results/render.html?scene=car" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/nerd-results/assets/models/car/input.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/nerd-results/render.html?scene=chair" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/nerd-results/assets/models/chair/input.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/nerd-results/render.html?scene=globe" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/nerd-results/assets/models/globe/input.jpg" alt="">
&lt;/a>
&lt;/div>
&lt;!-- ### Copyright
This material is posted here with permission of the IEEE. Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to [pubs-permissions@ieee.org](mailto:pubs-permissions@ieee.org). --></description></item><item><title>Two-shot Spatially-varying BRDF and Shape Estimation</title><link>https://markboss.me/news/cvpr20-code/</link><pubDate>Fri, 11 Sep 2020 00:00:00 +0000</pubDate><guid>https://markboss.me/news/cvpr20-code/</guid><description/></item><item><title>Two-shot Spatially-varying BRDF and Shape Estimation</title><link>https://markboss.me/publication/cvpr20-two-shot-brdf/</link><pubDate>Tue, 16 Jun 2020 00:00:00 +0000</pubDate><guid>https://markboss.me/publication/cvpr20-two-shot-brdf/</guid><description>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/CyC6PutoJO8" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h3 id="results">Results&lt;/h3>
&lt;div class="alert alert-note">
&lt;div>
Click the images for an interactive 3D visualization.
&lt;/div>
&lt;/div>
&lt;h4 id="aksoy-et-al---a-dataset-of-flash-and-ambient-illumination-pairs-from-the-crowd">Aksoy et al. - A Dataset of Flash and Ambient Illumination Pairs from the Crowd&lt;/h4>
&lt;div class="gallery">
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf0" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf0/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf1" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf1/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf2" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf2/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf3" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf3/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf4" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf4/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf5" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf5/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf6" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf6/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf7" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf7/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf8" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf8/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf9" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf9/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf10" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf10/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf11" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf11/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf12" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf12/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf13" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf13/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf14" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf14/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=fnf15" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/fnf15/input_flash.jpg" alt="">
&lt;/a>
&lt;/div>
&lt;h5 id="real-world-examples">Real-world Examples&lt;/h5>
&lt;div class="gallery">
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=rw0" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/rw0/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=rw1" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/rw1/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=rw2" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/rw2/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=rw3" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/rw3/input_flash.jpg" alt="">
&lt;/a>
&lt;/div>
&lt;h5 id="synthetic-examples">Synthetic Examples&lt;/h5>
&lt;div class="gallery">
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=syn0" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/syn0/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=syn1" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/syn1/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=syn2" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/syn2/input_flash.jpg" alt="">
&lt;/a>
&lt;a data-fancybox data-type="iframe" data-src="https://markboss.me/files/cvpr20-results/renderer.html?mat=syn3" href="javascript:;">
&lt;img class="fixed-width-img" src="https://markboss.me/files/cvpr20-results/predictions/syn3/input_flash.jpg" alt="">
&lt;/a>
&lt;/div>
&lt;h3 id="copyright">Copyright&lt;/h3>
&lt;p>This material is posted here with permission of the IEEE. Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by writing to &lt;a href="mailto:pubs-permissions@ieee.org">pubs-permissions@ieee.org&lt;/a>.&lt;/p></description></item><item><title>Two-shot Spatially-varying BRDF and Shape Estimation</title><link>https://markboss.me/news/cvpr20-accept/</link><pubDate>Mon, 24 Feb 2020 00:00:00 +0000</pubDate><guid>https://markboss.me/news/cvpr20-accept/</guid><description/></item><item><title>Infomark</title><link>https://markboss.me/project/infomark/</link><pubDate>Sat, 28 Dec 2019 00:00:00 +0000</pubDate><guid>https://markboss.me/project/infomark/</guid><description/></item><item><title>Single Image BRDF Parameter Estimation with a Conditional Adversarial Network</title><link>https://markboss.me/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/</link><pubDate>Fri, 11 Oct 2019 00:00:00 +0000</pubDate><guid>https://markboss.me/publication/single-image-brdf-parameter-estimation-with-conditional-adversarial-network/</guid><description/></item><item><title>Deep Dual Loss BRDF Parameter Estimation</title><link>https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/</link><pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate><guid>https://markboss.me/publication/deep-dual-loss-brdf-parameter-estimation/</guid><description/></item><item><title>Legal details</title><link>https://markboss.me/terms/</link><pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate><guid>https://markboss.me/terms/</guid><description>&lt;h3 id="legal-disclosure">Legal Disclosure&lt;/h3>
&lt;p>Information in accordance with Section 5 TMG&lt;/p>
&lt;p>Mark Boss&lt;br>
Bismarckstr. 114&lt;br>
72072 Tübingen&lt;/p>
&lt;h3 id="contact-information">Contact Information&lt;/h3>
&lt;p>E-Mail: &lt;a href="mailto:markboss@mailbox.org">markboss@mailbox.org&lt;/a>&lt;br>
Internet address: markboss.me&lt;/p>
&lt;h1 id="disclaimer">Disclaimer&lt;/h1>
&lt;h3 id="accountability-for-content">Accountability for content&lt;/h3>
&lt;p>The contents of our pages have been created with the utmost care. However, we cannot guarantee the contents' accuracy, completeness or topicality. According to statutory provisions, we are furthermore responsible for our own content on these web pages. In this matter, please note that we are not obliged to monitor the transmitted or saved information of third parties, or investigate circumstances pointing to illegal activity. Our obligations to remove or block the use of information under generally applicable laws remain unaffected by this as per §§ 8 to 10 of the Telemedia Act (TMG).&lt;/p>
&lt;h3 id="accountability-for-links">Accountability for links&lt;/h3>
&lt;p>Responsibility for the content of external links (to web pages of third parties) lies solely with the operators of the linked pages. No violations were evident to us at the time of linking. Should any legal infringement become known to us, we will remove the respective link immediately.&lt;/p>
&lt;h3 id="copyright">Copyright&lt;/h3>
&lt;p>Our web pages and their contents are subject to German copyright law. Unless expressly permitted by law, every form of utilizing, reproducing or processing works subject to copyright protection on our web pages requires the prior consent of the respective owner of the rights. Individual reproductions of a work are only allowed for private use. The materials from these pages are copyrighted and any unauthorized use may violate copyright laws.&lt;/p></description></item><item><title>Privacy Policy</title><link>https://markboss.me/privacy/</link><pubDate>Thu, 28 Jun 2018 00:00:00 +0100</pubDate><guid>https://markboss.me/privacy/</guid><description>&lt;p>Your privacy is important to us. It is Mark Boss' policy to respect your privacy regarding any information we may collect from you across our website, &lt;a href="https://www.markboss.me">https://www.markboss.me&lt;/a>, and other sites we own and operate.&lt;/p>
&lt;p>We only ask for personal information when we truly need it to provide a service to you. We collect it by fair and lawful means, with your knowledge and consent. We also let you know why we’re collecting it and how it will be used.&lt;/p>
&lt;p>We only retain collected information for as long as necessary to provide you with your requested service. What data we store, we’ll protect within commercially acceptable means to prevent loss and theft, as well as unauthorized access, disclosure, copying, use or modification.&lt;/p>
&lt;p>We don’t share any personally identifying information publicly or with third-parties, except when required to by law.&lt;/p>
&lt;p>Our website may link to external sites that are not operated by us. Please be aware that we have no control over the content and practices of these sites, and cannot accept responsibility or liability for their respective privacy policies.&lt;/p>
&lt;p>You are free to refuse our request for your personal information, with the understanding that we may be unable to provide you with some of your desired services.&lt;/p>
&lt;p>Your continued use of our website will be regarded as acceptance of our practices around privacy and personal information. If you have any questions about how we handle user data and personal information, feel free to contact us.&lt;/p>
&lt;p>This policy is effective as of 1 April 2020.&lt;/p></description></item><item><title>CNN-based BRDF parameter estimation</title><link>https://markboss.me/publication/master_thesis/</link><pubDate>Tue, 01 May 2018 00:00:00 +0000</pubDate><guid>https://markboss.me/publication/master_thesis/</guid><description/></item></channel></rss>